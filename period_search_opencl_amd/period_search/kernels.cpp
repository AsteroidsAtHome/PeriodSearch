const char* ocl_src_kernelSource =
"#define POINTS_MAX         1000             /* max number of data points in one lc. */\n"
"#define MAX_N_OBS         20000             /* max number of data points */\n"
"#define MAX_LC              200             /* max number of lightcurves */\n"
"#define MAX_LINE_LENGTH    1000             /* max length of line in an input file */\n"
"#define MAX_N_FAC          1000             /* max number of facets */\n"
"#define MAX_N_ITER          100             /* maximum number of iterations */\n"
"#define MAX_N_PAR           200             /* maximum number of parameters */\n"
"#define MAX_LM               10             /* maximum degree and order of sph. harm. */\n"
"#define N_PHOT_PAR            5             /* maximum number of parameters in scattering  law */\n"
"#define TINY                  1e-8          /* precision parameter for mu, mu0*/\n"
"#define N_POLES              10             /* number of initial poles */\n"
"\n"
"#define PI                 M_PI             /* 3.14159265358979323846 */\n"
"#define AU            149597870.691         /* Astronomical Unit [km] */\n"
"#define C_SPEED       299792458             /* speed of light [m/s]*/\n"
"\n"
"#define DEG2RAD      (PI / 180)\n"
"#define RAD2DEG      (180 / PI)\n"
"\n"
"#define BLOCK_DIM 128\n"
"#pragma OPENCL FP_CONTRACT ON\n"
"\n"
"#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n"
"#pragma OPENCL EXTENSION cl_khr_global_int32_base_atomics : enable\n"
"#pragma OPENCL EXTENSION cl_khr_global_int32_extended_atomics : enable\n"
"#pragma OPENCL EXTENSION cl_khr_local_int32_base_atomics : enable\n"
"#pragma OPENCL EXTENSION cl_khr_local_int32_extended_atomics : enable\n"
"\n"
"//struct __attribute__((packed)) freq_context\n"
"//struct mfreq_context\n"
"//struct __attribute__((aligned(8))) mfreq_context\n"
"//#ifdef NVIDIA\n"
"//struct mfreq_context\n"
"//#else\n"
"//typedef struct mfreq_context\n"
"//#endif\n"
"typedef struct mfreq_context\n"
"{\n"
"	//double* Area;\n"
"	//double* Dg;\n"
"	//double* alpha;\n"
"	//double* covar;\n"
"	//double* dytemp;\n"
"	//double* ytemp;\n"
"\n"
"	double Area[MAX_N_FAC + 1];\n"
"	double Dg[(MAX_N_FAC + 1) * (MAX_N_PAR + 1)];\n"
"	double alpha[(MAX_N_PAR + 1) * (MAX_N_PAR + 1)];\n"
"	double covar[(MAX_N_PAR + 1) * (MAX_N_PAR + 1)];\n"
"	double dytemp[(POINTS_MAX + 1) * (MAX_N_PAR + 1)];\n"
"	double ytemp[POINTS_MAX + 1];\n"
"\n"
"	double beta[MAX_N_PAR + 1];\n"
"	double atry[MAX_N_PAR + 1];\n"
"	double da[MAX_N_PAR + 1];\n"
"	double cg[MAX_N_PAR + 1];\n"
"	double Blmat[4][4];\n"
"	double Dblm[3][4][4];\n"
"	double jp_Scale[POINTS_MAX + 1];\n"
"	double jp_dphp_1[POINTS_MAX + 1];\n"
"	double jp_dphp_2[POINTS_MAX + 1];\n"
"	double jp_dphp_3[POINTS_MAX + 1];\n"
"	double e_1[POINTS_MAX + 1];\n"
"	double e_2[POINTS_MAX + 1];\n"
"	double e_3[POINTS_MAX + 1];\n"
"	double e0_1[POINTS_MAX + 1];\n"
"	double e0_2[POINTS_MAX + 1];\n"
"	double e0_3[POINTS_MAX + 1];\n"
"	double de[POINTS_MAX + 1][4][4];\n"
"	double de0[POINTS_MAX + 1][4][4];\n"
"	double dave[MAX_N_PAR + 1];\n"
"	double dyda[MAX_N_PAR + 1];\n"
"\n"
"	double sh_big[BLOCK_DIM];\n"
"	double chck[4];\n"
"	double pivinv;\n"
"	double ave;\n"
"	double freq;\n"
"	double Alamda;\n"
"	double Chisq;\n"
"	double Ochisq;\n"
"	double rchisq;\n"
"	double trial_chisq;\n"
"	double iter_diff, dev_old, dev_new;\n"
"\n"
"	int Niter;\n"
"	int np, np1, np2;\n"
"	int isInvalid, isAlamda, isNiter;\n"
"	int icol;\n"
"	//double conw_r;\n"
"\n"
"	int ipiv[MAX_N_PAR + 1];\n"
"	int indxc[MAX_N_PAR + 1];\n"
"	int indxr[MAX_N_PAR + 1];\n"
"	int sh_icol[BLOCK_DIM];\n"
"	int sh_irow[BLOCK_DIM];\n"
"} CUDA_LCC;\n"
"\n"
"//struct freq_context\n"
"//typedef struct __attribute__((aligned(8))) freq_context\n"
"//#ifdef NVIDIA\n"
"//struct freq_context\n"
"//#else\n"
"//typedef struct freq_context\n"
"//#endif\n"
"struct freq_context\n"
"{\n"
"	double Phi_0;\n"
"	double logCl;\n"
"	double cl;\n"
"	//double logC;\n"
"	double lambda_pole[N_POLES + 1];\n"
"	double beta_pole[N_POLES + 1];\n"
"\n"
"\n"
"	double par[4];\n"
"	double Alamda_start;\n"
"	double Alamda_incr;\n"
"\n"
"	//double cgFirst[MAX_N_PAR + 1];\n"
"	double tim[MAX_N_OBS + 1];\n"
"	double ee[MAX_N_OBS + 1][3];	// double* ee;\n"
"	double ee0[MAX_N_OBS + 1][3];	// double* ee0;\n"
"	double Sig[MAX_N_OBS + 1];\n"
"	double Weight[MAX_N_OBS + 1];\n"
"	double Brightness[MAX_N_OBS + 1];\n"
"	double Fc[MAX_N_FAC + 1][MAX_LM + 1];\n"
"	double Fs[MAX_N_FAC + 1][MAX_LM + 1];\n"
"	double Darea[MAX_N_FAC + 1];\n"
"	double Nor[MAX_N_FAC + 1][3];\n"
"	double Dsph[MAX_N_FAC + 1][MAX_N_PAR + 1];\n"
"	double Pleg[MAX_N_FAC + 1][MAX_LM + 1][MAX_LM + 1];\n"
"	double conw_r;\n"
"\n"
"	int ia[MAX_N_PAR + 1];\n"
"\n"
"	int Dg_block;\n"
"	int lastone;\n"
"	int lastma;\n"
"	int ma;\n"
"	int Mfit, Mfit1;\n"
"	int Mmax, Lmax;\n"
"	int n;\n"
"	int Ncoef, Ncoef0;\n"
"	int Numfac;\n"
"	int Numfac1;\n"
"	int Nphpar;\n"
"	int ndata;\n"
"	int Is_Precalc;\n"
"};\n"
"\n"
"//struct freq_result\n"
"//struct __attribute__((aligned(8))) freq_result\n"
"//#ifdef NVIDIA\n"
"//struct freq_result\n"
"//#else\n"
"//typedef struct freq_result\n"
"//#endif\n"
"struct freq_result\n"
"{\n"
"	double dark_best, per_best, dev_best, dev_best_x2, la_best, be_best, freq;\n"
"	int isReported, isInvalid, isNiter;\n"
"};\n"
"/*\n"
"    FROM stackoverflow: https://stackoverflow.com/questions/42856717/intrinsics-equivalent-to-the-cuda-type-casting-intrinsics-double2loint-doub\n"
"    You can express these operations via a union. This will not create extra overhead with modern compilers as long as optimization is on (nvcc -O3 ...).\n"
"*/\n"
"\n"
"//struct HiLo\n"
"//{\n"
"//    int lo;\n"
"//    int hi;\n"
"//};\n"
"//\n"
"//typedef struct HiLo hilo;\n"
"//\n"
"//union U {\n"
"//    double val;\n"
"//    hilo hiLo;\n"
"//};\n"
"//\n"
"//double HiLoint2double(int hi, int lo)\n"
"//{\n"
"//    union U u;\n"
"//\n"
"//    u.hiLo.hi = hi;\n"
"//    u.hiLo.lo = lo;\n"
"//\n"
"//    return u.val;\n"
"//}\n"
"\n"
"typedef union {\n"
"    double val;\n"
"    struct {\n"
"        int lo;\n"
"        int hi;\n"
"    };\n"
"} un;\n"
"\n"
"double HiLoint2double(int hi, int lo)\n"
"{\n"
"    /*union {\n"
"        double val;\n"
"        struct {\n"
"            int lo;\n"
"            int hi;\n"
"        };\n"
"    } u;*/\n"
"    un u;\n"
"\n"
"    u.hi = hi;\n"
"    u.lo = lo;\n"
"    return u.val;\n"
"}\n"
"\n"
"\n"
"int double2hiint(double val)\n"
"{\n"
"    un u;\n"
"    u.val = val;\n"
"    return u.hi;\n"
"}\n"
"\n"
"int double2loint(double val)\n"
"{\n"
"    un u;\n"
"    u.val = val;\n"
"    return u.lo;\n"
"}\n"
"\n"
"//int __double2hiint(double val)\n"
"//{\n"
"//    union {\n"
"//        double val;\n"
"//        struct {\n"
"//            int lo;\n"
"//            int hi;\n"
"//        };\n"
"//    } u;\n"
"//    u.val = val;\n"
"//\n"
"//    return u.hi;\n"
"//}\n"
"//\n"
"//int __double2loint(double val)\n"
"//{\n"
"//    union {\n"
"//        double val;\n"
"//        struct {\n"
"//            int lo;\n"
"//            int hi;\n"
"//        };\n"
"//    } u;\n"
"//    u.val = val;\n"
"//\n"
"//    return u.lo;\n"
"//}\n"
"//\n"
"//int2 __double2int2(double val) {\n"
"//    int2 result;\n"
"//\n"
"//    result.x = __double2hiint(val);\n"
"//    result.y = __double2loint(val);\n"
"//\n"
"//    return result;\n"
"//}\n"
"\n"
"void SwapDouble(double a, double b)\n"
"{\n"
"	double temp = a;\n"
"	a = b;\n"
"	b = temp;\n"
"} //beta, lambda rotation matrix and its derivatives\n"
"\n"
" //  8.11.2006\n"
"\n"
"\n"
"//#include <math.h>\n"
"//#include \"globals_CUDA.h\"\n"
"\n"
"void blmatrix(__global struct mfreq_context* CUDA_LCC, double bet, double lam)\n"
"{\n"
"	double cb, sb, cl, sl;\n"
"	int3 threadIdx, blockIdx;\n"
"	threadIdx.x = get_local_id(0);\n"
"	blockIdx.x = get_group_id(0);\n"
"\n"
"	cb = cos(bet);\n"
"	sb = sin(bet);\n"
"	cl = cos(lam);\n"
"	sl = sin(lam);\n"
"	(*CUDA_LCC).Blmat[1][1] = cb * cl;\n"
"	(*CUDA_LCC).Blmat[1][2] = cb * sl;\n"
"	(*CUDA_LCC).Blmat[1][3] = -sb;\n"
"	(*CUDA_LCC).Blmat[2][1] = -sl;\n"
"	(*CUDA_LCC).Blmat[2][2] = cl;\n"
"	(*CUDA_LCC).Blmat[2][3] = 0;\n"
"	(*CUDA_LCC).Blmat[3][1] = sb * cl;\n"
"	(*CUDA_LCC).Blmat[3][2] = sb * sl;\n"
"	(*CUDA_LCC).Blmat[3][3] = cb;\n"
"\n"
"	//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"	//{\n"
"	//	printf(\"bet: %10.7f, lam: %10.7f\\n\", bet, lam);\n"
"	//	printf(\"Blmat[1][1]: %10.7f, Blmat[2][1]: %10.7f, Blmat[3][1]: %10.7f\\n\", (*CUDA_LCC).Blmat[1][1], (*CUDA_LCC).Blmat[2][1], (*CUDA_LCC).Blmat[3][1]);\n"
"	//	printf(\"Blmat[1][2]: %10.7f, Blmat[2][2]: %10.7f, Blmat[3][2]: %10.7f\\n\", (*CUDA_LCC).Blmat[1][2], (*CUDA_LCC).Blmat[2][2], (*CUDA_LCC).Blmat[3][2]);\n"
"	//	printf(\"Blmat[1][3]: %10.7f, Blmat[2][3]: %10.7f, Blmat[3][3]: %10.7f\\n\", (*CUDA_LCC).Blmat[1][3], (*CUDA_LCC).Blmat[2][3], (*CUDA_LCC).Blmat[3][3]);\n"
"	//}\n"
"\n"
"	/* Ders. of Blmat w.r.t. bet */\n"
"	(*CUDA_LCC).Dblm[1][1][1] = -sb * cl;\n"
"	(*CUDA_LCC).Dblm[1][1][2] = -sb * sl;\n"
"	(*CUDA_LCC).Dblm[1][1][3] = -cb;\n"
"	(*CUDA_LCC).Dblm[1][2][1] = 0;\n"
"	(*CUDA_LCC).Dblm[1][2][2] = 0;\n"
"	(*CUDA_LCC).Dblm[1][2][3] = 0;\n"
"	(*CUDA_LCC).Dblm[1][3][1] = cb * cl;\n"
"	(*CUDA_LCC).Dblm[1][3][2] = cb * sl;\n"
"	(*CUDA_LCC).Dblm[1][3][3] = -sb;\n"
"	/* Ders. w.r.t. lam */\n"
"	(*CUDA_LCC).Dblm[2][1][1] = -cb * sl;\n"
"	(*CUDA_LCC).Dblm[2][1][2] = cb * cl;\n"
"	(*CUDA_LCC).Dblm[2][1][3] = 0;\n"
"	(*CUDA_LCC).Dblm[2][2][1] = -cl;\n"
"	(*CUDA_LCC).Dblm[2][2][2] = -sl;\n"
"	(*CUDA_LCC).Dblm[2][2][3] = 0;\n"
"	(*CUDA_LCC).Dblm[2][3][1] = -sb * sl;\n"
"	(*CUDA_LCC).Dblm[2][3][2] = sb * cl;\n"
"	(*CUDA_LCC).Dblm[2][3][3] = 0;\n"
"}\n"
" //Curvature function (and hence facet area) from Laplace series\n"
"\n"
" //  8.11.2006\n"
"\n"
"\n"
"void curv(\n"
"	__global struct mfreq_context* CUDA_LCC,\n"
"	__global struct freq_context* CUDA_CC,\n"
"	__global double* cg,\n"
"	int brtmpl,\n"
"	int brtmph)\n"
"{\n"
"	int n;\n"
"	double fsum, g;\n"
"	int3 blockIdx, threadIdx;\n"
"	blockIdx.x = get_group_id(0);\n"
"	threadIdx.x = get_local_id(0);\n"
"\n"
"	//        brtmpl:  1, 4, 7... 382\n"
"	//		  brtmph:  3, 6, 9... 288\n"
"	int q = 0;\n"
"	for (int i = brtmpl; i <= brtmph; i++, q++)\n"
"	{\n"
"		//if (blockIdx.x == 0)\n"
"		//	printf(\"i: %d\\n\", i);\n"
"\n"
"		g = 0;\n"
"		n = 0;\n"
"		for (int m = 0; m <= (*CUDA_CC).Mmax; m++) // Mmax = 6\n"
"		{\n"
"			for (int l = m; l <= (*CUDA_CC).Lmax; l++)  // Lmax = 6\n"
"			{\n"
"				n++;\n"
"				//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"				//	printf(\"cg[%3d]: %10.7f\\n\", n, cg[n]);\n"
"\n"
"				fsum = cg[n] * (*CUDA_CC).Fc[i][m];\n"
"				if (m != 0)\n"
"				{\n"
"					n++;\n"
"					//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"					//	printf(\"cg[%3d]: %10.7f\\n\", n, cg[n]);\n"
"\n"
"					fsum = fsum + cg[n] * (*CUDA_CC).Fs[i][m];\n"
"				}\n"
"\n"
"				g = g + (*CUDA_CC).Pleg[i][l][m] * fsum;\n"
"			}\n"
"		}\n"
"\n"
"		g = exp(g);\n"
"		(*CUDA_LCC).Area[i] = (*CUDA_CC).Darea[i] * g;\n"
"\n"
"		//if (blockIdx.x == 0)\n"
"		//	printf(\"[%3d - %3d] i: %3d\\n\", q, threadIdx.x, i);\n"
"\n"
"		//if (blockIdx.x == 0)\n"
"		//	printf(\"Area[%d]: %.7f\\n\", i, Area[i]);\n"
"\n"
"		for (int k = 1; k <= n; k++)\n"
"		{\n"
"			// 290(1 + 1 * 289)    ...    867(288 + 2 * 289)\n"
"			int idx = i + k * (*CUDA_CC).Numfac1;\n"
"			(*CUDA_LCC).Dg[idx] = g * (*CUDA_CC).Dsph[i][k];\n"
"\n"
"			//printf(\"Dg[%4d]: %.7f\\n\", i + k * (*CUDA_CC).Numfac1, (*CUDA_LCC).Dg[i + k * (*CUDA_CC).Numfac1]);\n"
"\n"
"			//if (blockIdx.x == 0 && i == 1)\n"
"			//	printf(\"[%d] i: %d, n: %d, k: %d, Dg[%4d]: %.7f\\n\", blockIdx.x, i, n, k, idx, (*CUDA_LCC).Dg[idx]);\n"
"\n"
"		}\n"
"	}\n"
"\n"
"	barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); 	//__syncthreads();\n"
"}\n"
"\n"
"void mrqcof_curve2(\n"
"	__global struct mfreq_context* CUDA_LCC,\n"
"	__global struct freq_context* CUDA_CC,\n"
"	__global double* alpha,\n"
"	__global double* beta,\n"
"	int inrel,\n"
"	int lpoints)\n"
"{\n"
"	int l, jp, j, k, m, lnp1, lnp2, Lpoints1 = lpoints + 1;\n"
"	double dy, sig2i, wt, ymod, coef1, coef, wght, ltrial_chisq;\n"
"\n"
"	int3 blockIdx, threadIdx;\n"
"	blockIdx.x = get_group_id(0);\n"
"	threadIdx.x = get_local_id(0);\n"
"\n"
"\n"
"	//precalc thread boundaries\n"
"	int tmph, tmpl;\n"
"	tmph = lpoints / BLOCK_DIM;\n"
"	if (lpoints % BLOCK_DIM) tmph++;\n"
"	tmpl = threadIdx.x * tmph;\n"
"	lnp1 = (*CUDA_LCC).np1 + tmpl;\n"
"	tmph = tmpl + tmph;\n"
"	if (tmph > lpoints) tmph = lpoints;\n"
"	tmpl++;\n"
"\n"
"	int matmph, matmpl;									// threadIdx.x == 1\n"
"	matmph = (*CUDA_CC).ma / BLOCK_DIM;					// 0\n"
"	if ((*CUDA_CC).ma % BLOCK_DIM) matmph++;			// 1\n"
"	matmpl = threadIdx.x * matmph;						// 1\n"
"	matmph = matmpl + matmph;							// 2\n"
"	if (matmph > (*CUDA_CC).ma) matmph = (*CUDA_CC).ma;\n"
"	matmpl++;											// 2\n"
"\n"
"	int latmph, latmpl;\n"
"	latmph = (*CUDA_CC).lastone / BLOCK_DIM;\n"
"	if ((*CUDA_CC).lastone % BLOCK_DIM) latmph++;\n"
"	latmpl = threadIdx.x * latmph;\n"
"	latmph = latmpl + latmph;\n"
"	if (latmph > (*CUDA_CC).lastone) latmph = (*CUDA_CC).lastone;\n"
"	latmpl++;\n"
"\n"
"	/*   if ((*CUDA_LCC).Lastcall != 1) always ==0\n"
"		 {*/\n"
"	if (inrel /*==1*/)\n"
"	{\n"
"		for (jp = tmpl; jp <= tmph; jp++)\n"
"		{\n"
"			lnp1++;\n"
"			int ixx = jp + 1 * Lpoints1;\n"
"			/* Set the size scale coeff. deriv. explicitly zero for relative lcurves */\n"
"			(*CUDA_LCC).dytemp[ixx] = 0;\n"
"\n"
"			//if (blockIdx.x == 0)\n"
"			//	printf(\"[%d][%d] dytemp[%3d]: %10.7f\\n\", blockIdx.x, jp, ixx, (*CUDA_LCC).dytemp[ixx]);\n"
"\n"
"			coef = (*CUDA_CC).Sig[lnp1] * lpoints / (*CUDA_LCC).ave;\n"
"\n"
"			//if (threadIdx.x == 0)\n"
"			//	printf(\"[%d][%3d][%d] coef: %10.7f\\n\", blockIdx.x, threadIdx.x, jp, coef);\n"
"\n"
"			double yytmp = (*CUDA_LCC).ytemp[jp];\n"
"			coef1 = yytmp / (*CUDA_LCC).ave;\n"
"\n"
"			//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"			//	printf(\"[Device | mrqcof_curve2_1] [%3d]  yytmp[%3d]: %10.7f, ave: %10.7f\\n\", threadIdx.x, jp, yytmp, (*CUDA_LCC).ave);\n"
"\n"
"			(*CUDA_LCC).ytemp[jp] = coef * yytmp;\n"
"\n"
"			//if (blockIdx.x == 0)\n"
"			//	printf(\"[Device][%d][%3d] ytemp[%3d]: %10.7f\\n\", blockIdx.x, threadIdx.x, jp, (*CUDA_LCC).ytemp[jp]);\n"
"\n"
"			ixx += Lpoints1;\n"
"\n"
"			//if (threadIdx.x == 0)\n"
"			//	printf(\"[%3d] jp[%3d] dytemp[%3d]: %10.7f\\n\", blockIdx.x, jp, ixx, (*CUDA_LCC).dytemp[ixx]);\n"
"\n"
"			for (l = 2; l <= (*CUDA_CC).ma; l++, ixx += Lpoints1)\n"
"			{\n"
"				(*CUDA_LCC).dytemp[ixx] = coef * ((*CUDA_LCC).dytemp[ixx] - coef1 * (*CUDA_LCC).dave[l]);\n"
"\n"
"				//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"				//	printf(\"[Device | mrqcof_curve2_1] [%3d]  coef1: %10.7f, dave[%3d]: %10.7f, dytemp[%3d]: %10.7f\\n\",\n"
"				//		threadIdx.x, coef1, l, (*CUDA_LCC).dave[l], ixx, (*CUDA_LCC).dytemp[ixx]);\n"
"			}\n"
"		}\n"
"	}\n"
"\n"
"	barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); 	//__syncthreads();\n"
"\n"
"	if (threadIdx.x == 0)\n"
"	{\n"
"		(*CUDA_LCC).np1 += lpoints;\n"
"	}\n"
"\n"
"	lnp2 = (*CUDA_LCC).np2;\n"
"	ltrial_chisq = (*CUDA_LCC).trial_chisq;\n"
"\n"
"	if ((*CUDA_CC).ia[1]) //not relative\n"
"	{\n"
"		for (jp = 1; jp <= lpoints; jp++)\n"
"		{\n"
"			ymod = (*CUDA_LCC).ytemp[jp];\n"
"\n"
"			int ixx = jp + matmpl * Lpoints1;\n"
"			for (l = matmpl; l <= matmph; l++, ixx += Lpoints1)\n"
"				(*CUDA_LCC).dyda[l] = (*CUDA_LCC).dytemp[ixx];\n"
"			barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"\n"
"			lnp2++;\n"
"\n"
"			//xx = tex1Dfetch(texsig, lnp2);\n"
"			//sig2i = 1 / (__hiloint2double(xx.y, xx.x) * __hiloint2double(xx.y, xx.x));\n"
"			sig2i = 1 / ((*CUDA_CC).Sig[lnp2] * (*CUDA_CC).Sig[lnp2]);\n"
"\n"
"			//xx = tex1Dfetch(texWeight, lnp2);\n"
"			//wght = __hiloint2double(xx.y, xx.x);\n"
"			wght = (*CUDA_CC).Weight[lnp2];\n"
"\n"
"			//xx = tex1Dfetch(texbrightness, lnp2);\n"
"			//dy = __hiloint2double(xx.y, xx.x) - ymod;\n"
"			dy = (*CUDA_CC).Brightness[lnp2] - ymod;\n"
"\n"
"			j = 0;\n"
"			//\n"
"			double sig2iwght = sig2i * wght;\n"
"			//\n"
"			for (l = 1; l <= (*CUDA_CC).lastone; l++)\n"
"			{\n"
"				j++;\n"
"				wt = (*CUDA_LCC).dyda[l] * sig2iwght;\n"
"				//				   k = 0;\n"
"				//precalc thread boundaries\n"
"				tmph = l / BLOCK_DIM;\n"
"				if (l % BLOCK_DIM) tmph++;\n"
"				tmpl = threadIdx.x * tmph;\n"
"				tmph = tmpl + tmph;\n"
"				if (tmph > l) tmph = l;\n"
"				tmpl++;\n"
"				for (m = tmpl; m <= tmph; m++)\n"
"				{\n"
"					//				  k++;\n"
"					alpha[j * (*CUDA_CC).Mfit1 + m] = alpha[j * (*CUDA_CC).Mfit1 + m] + wt * (*CUDA_LCC).dyda[m];\n"
"				} /* m */\n"
"				barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"				if (threadIdx.x == 0)\n"
"				{\n"
"					beta[j] = beta[j] + dy * wt;\n"
"				}\n"
"				barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"			} /* l */\n"
"			for (; l <= (*CUDA_CC).lastma; l++)\n"
"			{\n"
"				if ((*CUDA_CC).ia[l])\n"
"				{\n"
"					j++;\n"
"					wt = (*CUDA_LCC).dyda[l] * sig2iwght;\n"
"					//				   k = 0;\n"
"\n"
"					for (m = latmpl; m <= latmph; m++)\n"
"					{\n"
"						//					  k++;\n"
"						alpha[j * (*CUDA_CC).Mfit1 + m] = alpha[j * (*CUDA_CC).Mfit1 + m] + wt * (*CUDA_LCC).dyda[m];\n"
"					} /* m */\n"
"					barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"					if (threadIdx.x == 0)\n"
"					{\n"
"						k = (*CUDA_CC).lastone;\n"
"						m = (*CUDA_CC).lastone + 1;\n"
"						for (; m <= l; m++)\n"
"						{\n"
"							if ((*CUDA_CC).ia[m])\n"
"							{\n"
"								k++;\n"
"								alpha[j * (*CUDA_CC).Mfit1 + k] = alpha[j * (*CUDA_CC).Mfit1 + k] + wt * (*CUDA_LCC).dyda[m];\n"
"							}\n"
"						} /* m */\n"
"						beta[j] = beta[j] + dy * wt;\n"
"					}\n"
"					barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"				}\n"
"			} /* l */\n"
"			ltrial_chisq = ltrial_chisq + dy * dy * sig2iwght;\n"
"		} /* jp */\n"
"	}\n"
"	else //relative ia[1]==0\n"
"	{\n"
"\n"
"		//if (threadIdx.x == 0)\n"
"		//	printf(\"[%d] lastone: %3d\\n\", blockIdx.x, (*CUDA_CC).lastone);\n"
"\n"
"		for (jp = 1; jp <= lpoints; jp++)\n"
"		{\n"
"			ymod = (*CUDA_LCC).ytemp[jp];\n"
"\n"
"			//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"			//	printf(\"Curve2_2b >>> [%3d][%3d] jp[%3d] ymod: %10.7f\\n\", blockIdx.x, threadIdx.x, jp, ymod);\n"
"\n"
"			int ixx = jp + matmpl * Lpoints1;\n"
"			for (l = matmpl; l <= matmph; l++, ixx += Lpoints1)\n"
"			{\n"
"				(*CUDA_LCC).dyda[l] = (*CUDA_LCC).dytemp[ixx];  // jp[1] dytemp[315] 0.0 - ?!?  must be -1051420.6747227\n"
"\n"
"				//if (blockIdx.x == 0 && threadIdx.x == 1 && jp == 1)\n"
"				//	printf(\"[%2d][%3d] dytemp[%d]: %10.7f\\n\", blockIdx.x, jp, ixx, (*CUDA_LCC).dytemp[ixx]);\n"
"			}\n"
"			barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"\n"
"			lnp2++;\n"
"\n"
"			//xx = tex1Dfetch(texsig, lnp2);\n"
"			//sig2i = 1 / (__hiloint2double(xx.y, xx.x) * __hiloint2double(xx.y, xx.x));\n"
"			sig2i = 1 / ((*CUDA_CC).Sig[lnp2] * (*CUDA_CC).Sig[lnp2]);\n"
"\n"
"			//xx = tex1Dfetch(texWeight, lnp2);\n"
"			//wght = __hiloint2double(xx.y, xx.x);\n"
"			wght = (*CUDA_CC).Weight[lnp2];\n"
"\n"
"			//xx = tex1Dfetch(texbrightness, lnp2);\n"
"			//dy = __hiloint2double(xx.y, xx.x) - ymod;\n"
"			dy = (*CUDA_CC).Brightness[lnp2] - ymod;\n"
"\n"
"			//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"			//	printf(\"Curve2_2b >>> [%3d][%3d] jp[%3d] sig2i: %10.7f, wght: %10.7f, dy: %10.7f\\n\", blockIdx.x, threadIdx.x, jp, sig2i, wght, dy);  // dy - ?\n"
"\n"
"			j = 0;\n"
"			//\n"
"			double sig2iwght = sig2i * wght;\n"
"			//l==1\n"
"			//\n"
"			for (l = 2; l <= (*CUDA_CC).lastone; l++)\n"
"			{\n"
"\n"
"				j++;\n"
"				wt = (*CUDA_LCC).dyda[l] * sig2iwght; // jp[1]  dyda[2] == 0    - ?!? must be -1051420.6747227   *) See dytemp[]\n"
"													  // jp 2, dyda[9] == 0 - ?!? must be 7.9447669\n"
"\n"
"				//if (blockIdx.x == 0 && threadIdx.x == 1 && jp == 1 && j == 1)\n"
"				//	printf(\"[%2d][%2d] jp[%3d] j[%3d] wt: %10.7f, dyda[%d]: %10.7f, sig2iwght: %10.7f\\n\",\n"
"				//		blockIdx.x, threadIdx.x, jp, j, wt, l, (*CUDA_LCC).dyda[l], sig2iwght);\n"
"\n"
"				//				   k = 0;\n"
"				//precalc thread boundaries\n"
"				tmph = l / BLOCK_DIM;\n"
"				if (l % BLOCK_DIM) tmph++;\n"
"				tmpl = threadIdx.x * tmph;\n"
"				tmph = tmpl + tmph;\n"
"				if (tmph > l) tmph = l;\n"
"				tmpl++;\n"
"				//m==1\n"
"				if (tmpl == 1) tmpl++;\n"
"				//\n"
"				for (m = tmpl; m <= tmph; m++)\n"
"				{\n"
"					//if (blockIdx.x == 0)\n"
"					//	printf(\"[%3d] tmpl: %3d, tmph: %3d\\n\", threadIdx.x, tmpl, tmph);\n"
"					//if (blockIdx.x == 0 && threadIdx.x == 1)\n"
"					//	printf(\".\");\n"
"					//					  k++;\n"
"					alpha[j * (*CUDA_CC).Mfit1 + m - 1] = alpha[j * (*CUDA_CC).Mfit1 + m - 1] + wt * (*CUDA_LCC).dyda[m];\n"
"\n"
"					//int qq = j * (*CUDA_CC).Mfit1 + m - 1;											// After the \"_\" in  Mrqcof1Curve2 \"wt\" & \"dyda[2]\" has ZEROES - ?!?\n"
"					//if (blockIdx.x == 0 && threadIdx.x == 1 && l == 2) // j == 1 like l = 2\n"
"					//	printf(\"curv2_2b>>>> [%2d][%3d] l[%3d] jp[%3d] alpha[%4d]: %10.7f, wt: %10.7f, dyda[%3d]: %10.7f\\n\",\n"
"					//		blockIdx.x, threadIdx.x, l, jp, qq, (*CUDA_LCC).alpha[qq], wt, m, (*CUDA_LCC).dyda[m]);\n"
"				} /* m */\n"
"				barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"				if (threadIdx.x == 0)\n"
"				{\n"
"					beta[j] = beta[j] + dy * wt;\n"
"				}\n"
"				barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"			} /* l */\n"
"			for (; l <= (*CUDA_CC).lastma; l++)\n"
"			{\n"
"\n"
"				if ((*CUDA_CC).ia[l])\n"
"				{\n"
"					j++;\n"
"					wt = (*CUDA_LCC).dyda[l] * sig2iwght;\n"
"					//				   k = 0;\n"
"\n"
"					tmpl = latmpl;\n"
"					//m==1\n"
"					if (tmpl == 1) tmpl++;\n"
"					//\n"
"					for (m = tmpl; m <= latmph; m++)\n"
"					{\n"
"						//k++;\n"
"						alpha[j * (*CUDA_CC).Mfit1 + m - 1] = alpha[j * (*CUDA_CC).Mfit1 + m - 1] + wt * (*CUDA_LCC).dyda[m];\n"
"					} /* m */\n"
"					barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"					if (threadIdx.x == 0)\n"
"					{\n"
"						k = (*CUDA_CC).lastone - 1;\n"
"						m = (*CUDA_CC).lastone + 1;\n"
"						for (; m <= l; m++)\n"
"						{\n"
"							if ((*CUDA_CC).ia[m])\n"
"							{\n"
"								k++;\n"
"								alpha[j * (*CUDA_CC).Mfit1 + k] = alpha[j * (*CUDA_CC).Mfit1 + k] + wt * (*CUDA_LCC).dyda[m];\n"
"							}\n"
"						} /* m */\n"
"						beta[j] = beta[j] + dy * wt;\n"
"					}\n"
"					barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"				}\n"
"			} /* l */\n"
"			ltrial_chisq = ltrial_chisq + dy * dy * sig2iwght;\n"
"		} /* jp */\n"
"	}\n"
"	//     } always ==0 // Lastcall != 1\n"
"\n"
"	 // if (((*CUDA_LCC).Lastcall == 1) && (CUDA_Inrel[i] == 1)) always ==0\n"
"		//(*CUDA_LCC).Sclnw[i] = (*CUDA_LCC).Scale * CUDA_Lpoints[i] * CUDA_sig[np]/ave;\n"
"\n"
"	if (threadIdx.x == 0)\n"
"	{\n"
"		//printf(\"[%d] ltrial_chisq: %10.7f\\n\", blockIdx.x, ltrial_chisq);\n"
"\n"
"		(*CUDA_LCC).np2 = lnp2;\n"
"		(*CUDA_LCC).trial_chisq = ltrial_chisq;\n"
"	}\n"
"}\n"
"\n"
"//computes integrated brightness of all visible and iluminated areas\n"
"//  and its derivatives\n"
"\n"
"//  8.11.2006\n"
"\n"
"\n"
"void matrix_neo(\n"
"	__global struct mfreq_context* CUDA_LCC,\n"
"	__global struct freq_context* CUDA_CC,\n"
"	__global double* cg,\n"
"	int lnp1,\n"
"	int Lpoints,\n"
"	int num)\n"
"{\n"
"	__private double f, cf, sf, pom, pom0, alpha;\n"
"	__private double ee_1, ee_2, ee_3, ee0_1, ee0_2, ee0_3, t, tmat;\n"
"	__private int lnp;\n"
"\n"
"	int3 threadIdx, blockIdx;\n"
"	threadIdx.x = get_local_id(0);\n"
"	blockIdx.x = get_group_id(0);\n"
"\n"
"	int brtmph, brtmpl;\n"
"	brtmph = Lpoints / BLOCK_DIM;\n"
"	if (Lpoints % BLOCK_DIM) brtmph++;\n"
"	brtmpl = threadIdx.x * brtmph;\n"
"	brtmph = brtmpl + brtmph;\n"
"	if (brtmph > Lpoints) brtmph = Lpoints;\n"
"	brtmpl++;\n"
"\n"
"	//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"	//{\n"
"	//	printf(\"Blmat[1][1]: %10.7f, Blmat[2][1]: %10.7f, Blmat[3][1]: %10.7f\\n\", (*CUDA_LCC).Blmat[1][1], (*CUDA_LCC).Blmat[2][1], (*CUDA_LCC).Blmat[3][1]);\n"
"	//	printf(\"Blmat[1][2]: %10.7f, Blmat[2][2]: %10.7f, Blmat[3][2]: %10.7f\\n\", (*CUDA_LCC).Blmat[1][2], (*CUDA_LCC).Blmat[2][2], (*CUDA_LCC).Blmat[3][2]);\n"
"	//	printf(\"Blmat[1][3]: %10.7f, Blmat[2][3]: %10.7f, Blmat[3][3]: %10.7f\\n\", (*CUDA_LCC).Blmat[1][3], (*CUDA_LCC).Blmat[2][3], (*CUDA_LCC).Blmat[3][3]);\n"
"	//}\n"
"\n"
"	lnp = lnp1 + brtmpl - 1;\n"
"	//printf(\"lnp: %3d = lnp1: %3d + brtmpl: %3d - 1 | lnp++: %3d\\n\", lnp, lnp1, brtmpl, lnp + 1);\n"
"\n"
"	int q = (*CUDA_CC).Ncoef0 + 2;\n"
"	//if (blockIdx.x == 0)\n"
"	//	printf(\"[neo] [%3d] cg[%3d]: %10.7f\\n\", blockIdx.x,  q, (*CUDA_LCC).cg[q]);\n"
"\n"
"	for (int jp = brtmpl; jp <= brtmph; jp++)\n"
"	{\n"
"		lnp++;\n"
"\n"
"		ee_1 = (*CUDA_CC).ee[lnp][0];		// position vectors\n"
"		ee0_1 = (*CUDA_CC).ee0[lnp][0];\n"
"		ee_2 = (*CUDA_CC).ee[lnp][1];\n"
"		ee0_2 = (*CUDA_CC).ee0[lnp][1];\n"
"		ee_3 = (*CUDA_CC).ee[lnp][2];\n"
"		ee0_3 = (*CUDA_CC).ee0[lnp][2];\n"
"		t = (*CUDA_CC).tim[lnp];\n"
"\n"
"		//if (blockIdx.x == 0)\n"
"		//	printf(\"jp[%3d] lnp[%3d], %10.7f, %10.7f, %10.7f, %10.7f, %10.7f, %10.7f\\n\",\n"
"		//		jp, lnp, ee_1, ee_2, ee_3, ee0_1, ee0_2, ee0_3);\n"
"\n"
"		//printf(\"tim[%3d]: %10.7f\\n\", lnp, t);\n"
"		//printf(\"lnp: %3d, ee[%d]: %.7f, ee0[%d]: %.7f\\n\", lnp, lnp * 3 + 0, (*CUDA_CC).ee[lnp][0], lnp, (*CUDA_CC).ee0[lnp][0]);\n"
"\n"
"		alpha = acos(ee_1 * ee0_1 + ee_2 * ee0_2 + ee_3 * ee0_3);\n"
"\n"
"\n"
"		//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"		//	printf(\"[neo] alpha[%3d]: %.7f, cg[%3d]: %10.7f\\n\", jp, alpha, q, (*CUDA_LCC).cg[q]);\n"
"\n"
"		/* Exp-lin model (const.term=1.) */\n"
"		double f = exp(-alpha / cg[(*CUDA_CC).Ncoef0 + 2]);	//f is temp here\n"
"\n"
"		//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"		//	printf(\"[neo] [%2d][%3d] jp[%3d] f: %10.7f, cg[%3d] %10.7f, alpha %10.7f\\n\",\n"
"		//		blockIdx.x, threadIdx.x, jp, f, (*CUDA_CC).Ncoef0 + 2, cg[(*CUDA_CC).Ncoef0 + 2], alpha);\n"
"\n"
"		(*CUDA_LCC).jp_Scale[jp] = 1 + cg[(*CUDA_CC).Ncoef0 + 1] * f + (cg[(*CUDA_CC).Ncoef0 + 3] * alpha);\n"
"		(*CUDA_LCC).jp_dphp_1[jp] = f;\n"
"		(*CUDA_LCC).jp_dphp_2[jp] = cg[(*CUDA_CC).Ncoef0 + 1] * f * alpha / (cg[(*CUDA_CC).Ncoef0 + 2] * cg[(*CUDA_CC).Ncoef0 + 2]);\n"
"		(*CUDA_LCC).jp_dphp_3[jp] = alpha;\n"
"\n"
"		//if (blockIdx.x == 0)\n"
"		//	printf(\"[neo] [%d][%3d] jp_Scale[%3d]: %10.7f, jp_dphp_1[]: %10.7F, jp_dphp_2[]: %10.7f, jp_dphp_3[]: %10.7f\\n\",\n"
"		//		blockIdx.x, threadIdx.x, jp, (*CUDA_LCC).jp_Scale[jp], (*CUDA_LCC).jp_dphp_1[jp], (*CUDA_LCC).jp_dphp_2[jp], (*CUDA_LCC).jp_dphp_3[jp]);\n"
"\n"
"		//  matrix start\n"
"		f = cg[(*CUDA_CC).Ncoef0] * t + (*CUDA_CC).Phi_0;\n"
"		f = fmod(f, 2 * PI); /* may give little different results than Mikko\'s */\n"
"		cf = cos(f);\n"
"		sf = sin(f);\n"
"\n"
"		//if (threadIdx.x == 0)\n"
"		//	printf(\"jp[%3d] [%3d] cf: %10.7f, sf: %10.7f\\n\", jp, blockIdx.x, cf, sf);\n"
"\n"
"		//if (num == 1 && blockIdx.x == 0 && jp == brtmpl)\n"
"		//{\n"
"		//	printf(\"[%2d][%3d][%3d] f: % .6f, cosF: % .6f, sinF: % .6f\\n\", blockIdx.x, threadIdx.x, jp, f, cf, sf);\n"
"		//}\n"
"\n"
"		//	/* rotation matrix, Z axis, angle f */\n"
"\n"
"		tmat = cf * (*CUDA_LCC).Blmat[1][1] + sf * (*CUDA_LCC).Blmat[2][1] + 0 * (*CUDA_LCC).Blmat[3][1];\n"
"		pom = tmat * ee_1;\n"
"		pom0 = tmat * ee0_1;\n"
"		tmat = cf * (*CUDA_LCC).Blmat[1][2] + sf * (*CUDA_LCC).Blmat[2][2] + 0 * (*CUDA_LCC).Blmat[3][2];\n"
"		pom += tmat * ee_2;\n"
"		pom0 += tmat * ee0_2;\n"
"		tmat = cf * (*CUDA_LCC).Blmat[1][3] + sf * (*CUDA_LCC).Blmat[2][3] + 0 * (*CUDA_LCC).Blmat[3][3];\n"
"		(*CUDA_LCC).e_1[jp] = pom + tmat * ee_3;\n"
"		(*CUDA_LCC).e0_1[jp] = pom0 + tmat * ee0_3;\n"
"\n"
"		//if (blockIdx.x == 0)\n"
"		//	printf(\"[%3d] jp[%3d] %10.7f, %10.7f\\n\", threadIdx.x, jp, (*CUDA_LCC).e_1[jp], (*CUDA_LCC).e0_1[jp]);\n"
"\n"
"		tmat = (-sf) * (*CUDA_LCC).Blmat[1][1] + cf * (*CUDA_LCC).Blmat[2][1] + 0 * (*CUDA_LCC).Blmat[3][1];\n"
"		pom = tmat * ee_1;\n"
"		pom0 = tmat * ee0_1;\n"
"		tmat = (-sf) * (*CUDA_LCC).Blmat[1][2] + cf * (*CUDA_LCC).Blmat[2][2] + 0 * (*CUDA_LCC).Blmat[3][2];\n"
"		pom += tmat * ee_2;\n"
"		pom0 += tmat * ee0_2;\n"
"		tmat = (-sf) * (*CUDA_LCC).Blmat[1][3] + cf * (*CUDA_LCC).Blmat[2][3] + 0 * (*CUDA_LCC).Blmat[3][3];\n"
"		(*CUDA_LCC).e_2[jp] = pom + tmat * ee_3;\n"
"		(*CUDA_LCC).e0_2[jp] = pom0 + tmat * ee0_3;\n"
"\n"
"		tmat = 0 * (*CUDA_LCC).Blmat[1][1] + 0 * (*CUDA_LCC).Blmat[2][1] + 1 * (*CUDA_LCC).Blmat[3][1];\n"
"		pom = tmat * ee_1;\n"
"		pom0 = tmat * ee0_1;\n"
"		tmat = 0 * (*CUDA_LCC).Blmat[1][2] + 0 * (*CUDA_LCC).Blmat[2][2] + 1 * (*CUDA_LCC).Blmat[3][2];\n"
"		pom += tmat * ee_2;\n"
"		pom0 += tmat * ee0_2;\n"
"		tmat = 0 * (*CUDA_LCC).Blmat[1][3] + 0 * (*CUDA_LCC).Blmat[2][3] + 1 * (*CUDA_LCC).Blmat[3][3];\n"
"		(*CUDA_LCC).e_3[jp] = pom + tmat * ee_3;\n"
"		(*CUDA_LCC).e0_3[jp] = pom0 + tmat * ee0_3;\n"
"\n"
"		tmat = cf * (*CUDA_LCC).Dblm[1][1][1] + sf * (*CUDA_LCC).Dblm[1][2][1] + 0 * (*CUDA_LCC).Dblm[1][3][1];\n"
"		pom = tmat * ee_1;\n"
"		pom0 = tmat * ee0_1;\n"
"		tmat = cf * (*CUDA_LCC).Dblm[1][1][2] + sf * (*CUDA_LCC).Dblm[1][2][2] + 0 * (*CUDA_LCC).Dblm[1][3][2];\n"
"		pom += tmat * ee_2;\n"
"		pom0 += tmat * ee0_2;\n"
"		tmat = cf * (*CUDA_LCC).Dblm[1][1][3] + sf * (*CUDA_LCC).Dblm[1][2][3] + 0 * (*CUDA_LCC).Dblm[1][3][3];\n"
"		(*CUDA_LCC).de[jp][1][1] = pom + tmat * ee_3;\n"
"		(*CUDA_LCC).de0[jp][1][1] = pom0 + tmat * ee0_3;\n"
"\n"
"		tmat = cf * (*CUDA_LCC).Dblm[2][1][1] + sf * (*CUDA_LCC).Dblm[2][2][1] + 0 * (*CUDA_LCC).Dblm[2][3][1];\n"
"		pom = tmat * ee_1;\n"
"		pom0 = tmat * ee0_1;\n"
"		tmat = cf * (*CUDA_LCC).Dblm[2][1][2] + sf * (*CUDA_LCC).Dblm[2][2][2] + 0 * (*CUDA_LCC).Dblm[2][3][2];\n"
"		pom += tmat * ee_2;\n"
"		pom0 += tmat * ee0_2;\n"
"		tmat = cf * (*CUDA_LCC).Dblm[2][1][3] + sf * (*CUDA_LCC).Dblm[2][2][3] + 0 * (*CUDA_LCC).Dblm[2][3][3];\n"
"		(*CUDA_LCC).de[jp][1][2] = pom + tmat * ee_3;\n"
"		(*CUDA_LCC).de0[jp][1][2] = pom0 + tmat * ee0_3;\n"
"\n"
"		tmat = (-t * sf) * (*CUDA_LCC).Blmat[1][1] + (t * cf) * (*CUDA_LCC).Blmat[2][1] + 0 * (*CUDA_LCC).Blmat[3][1];\n"
"		pom = tmat * ee_1;\n"
"		pom0 = tmat * ee0_1;\n"
"		tmat = (-t * sf) * (*CUDA_LCC).Blmat[1][2] + (t * cf) * (*CUDA_LCC).Blmat[2][2] + 0 * (*CUDA_LCC).Blmat[3][2];\n"
"		pom += tmat * ee_2;\n"
"		pom0 += tmat * ee0_2;\n"
"		tmat = (-t * sf) * (*CUDA_LCC).Blmat[1][3] + (t * cf) * (*CUDA_LCC).Blmat[2][3] + 0 * (*CUDA_LCC).Blmat[3][3];\n"
"		(*CUDA_LCC).de[jp][1][3] = pom + tmat * ee_3;\n"
"		(*CUDA_LCC).de0[jp][1][3] = pom0 + tmat * ee0_3;\n"
"\n"
"		tmat = -sf * (*CUDA_LCC).Dblm[1][1][1] + cf * (*CUDA_LCC).Dblm[1][2][1] + 0 * (*CUDA_LCC).Dblm[1][3][1];\n"
"		pom = tmat * ee_1;\n"
"		pom0 = tmat * ee0_1;\n"
"		tmat = -sf * (*CUDA_LCC).Dblm[1][1][2] + cf * (*CUDA_LCC).Dblm[1][2][2] + 0 * (*CUDA_LCC).Dblm[1][3][2];\n"
"		pom += tmat * ee_2;\n"
"		pom0 += tmat * ee0_2;\n"
"		tmat = -sf * (*CUDA_LCC).Dblm[1][1][3] + cf * (*CUDA_LCC).Dblm[1][2][3] + 0 * (*CUDA_LCC).Dblm[1][3][3];\n"
"		(*CUDA_LCC).de[jp][2][1] = pom + tmat * ee_3;\n"
"		(*CUDA_LCC).de0[jp][2][1] = pom0 + tmat * ee0_3;\n"
"\n"
"		tmat = -sf * (*CUDA_LCC).Dblm[2][1][1] + cf * (*CUDA_LCC).Dblm[2][2][1] + 0 * (*CUDA_LCC).Dblm[2][3][1];\n"
"		pom = tmat * ee_1;\n"
"		pom0 = tmat * ee0_1;\n"
"		tmat = -sf * (*CUDA_LCC).Dblm[2][1][2] + cf * (*CUDA_LCC).Dblm[2][2][2] + 0 * (*CUDA_LCC).Dblm[2][3][2];\n"
"		pom += tmat * ee_2;\n"
"		pom0 += tmat * ee0_2;\n"
"		tmat = -sf * (*CUDA_LCC).Dblm[2][1][3] + cf * (*CUDA_LCC).Dblm[2][2][3] + 0 * (*CUDA_LCC).Dblm[2][3][3];\n"
"		(*CUDA_LCC).de[jp][2][2] = pom + tmat * ee_3;\n"
"		(*CUDA_LCC).de0[jp][2][2] = pom0 + tmat * ee0_3;\n"
"\n"
"		tmat = (-t * cf) * (*CUDA_LCC).Blmat[1][1] + (-t * sf) * (*CUDA_LCC).Blmat[2][1] + 0 * (*CUDA_LCC).Blmat[3][1];\n"
"		pom = tmat * ee_1;\n"
"		pom0 = tmat * ee0_1;\n"
"		tmat = (-t * cf) * (*CUDA_LCC).Blmat[1][2] + (-t * sf) * (*CUDA_LCC).Blmat[2][2] + 0 * (*CUDA_LCC).Blmat[3][2];\n"
"		pom += tmat * ee_2;\n"
"		pom0 += tmat * ee0_2;\n"
"		tmat = (-t * cf) * (*CUDA_LCC).Blmat[1][3] + (-t * sf) * (*CUDA_LCC).Blmat[2][3] + 0 * (*CUDA_LCC).Blmat[3][3];\n"
"		(*CUDA_LCC).de[jp][2][3] = pom + tmat * ee_3;\n"
"		(*CUDA_LCC).de0[jp][2][3] = pom0 + tmat * ee0_3;\n"
"\n"
"		tmat = 0 * (*CUDA_LCC).Dblm[1][1][1] + 0 * (*CUDA_LCC).Dblm[1][2][1] + 1 * (*CUDA_LCC).Dblm[1][3][1];\n"
"		pom = tmat * ee_1;\n"
"		pom0 = tmat * ee0_1;\n"
"		tmat = 0 * (*CUDA_LCC).Dblm[1][1][2] + 0 * (*CUDA_LCC).Dblm[1][2][2] + 1 * (*CUDA_LCC).Dblm[1][3][2];\n"
"		pom += tmat * ee_2;\n"
"		pom0 += tmat * ee0_2;\n"
"		tmat = 0 * (*CUDA_LCC).Dblm[1][1][3] + 0 * (*CUDA_LCC).Dblm[1][2][3] + 1 * (*CUDA_LCC).Dblm[1][3][3];\n"
"		(*CUDA_LCC).de[jp][3][1] = pom + tmat * ee_3;\n"
"		(*CUDA_LCC).de0[jp][3][1] = pom0 + tmat * ee0_3;\n"
"\n"
"		tmat = 0 * (*CUDA_LCC).Dblm[2][1][1] + 0 * (*CUDA_LCC).Dblm[2][2][1] + 1 * (*CUDA_LCC).Dblm[2][3][1];\n"
"		pom = tmat * ee_1;\n"
"		pom0 = tmat * ee0_1;\n"
"		tmat = 0 * (*CUDA_LCC).Dblm[2][1][2] + 0 * (*CUDA_LCC).Dblm[2][2][2] + 1 * (*CUDA_LCC).Dblm[2][3][2];\n"
"		pom += tmat * ee_2;\n"
"		pom0 += tmat * ee0_2;\n"
"		tmat = 0 * (*CUDA_LCC).Dblm[2][1][3] + 0 * (*CUDA_LCC).Dblm[2][2][3] + 1 * (*CUDA_LCC).Dblm[2][3][3];\n"
"		(*CUDA_LCC).de[jp][3][2] = pom + tmat * ee_3;\n"
"		(*CUDA_LCC).de0[jp][3][2] = pom0 + tmat * ee0_3;\n"
"\n"
"		tmat = 0 * (*CUDA_LCC).Blmat[1][1] + 0 * (*CUDA_LCC).Blmat[2][1] + 0 * (*CUDA_LCC).Blmat[3][1];\n"
"		pom = tmat * ee_1;\n"
"		pom0 = tmat * ee0_1;\n"
"		tmat = 0 * (*CUDA_LCC).Blmat[1][2] + 0 * (*CUDA_LCC).Blmat[2][2] + 0 * (*CUDA_LCC).Blmat[3][2];\n"
"		pom += tmat * ee_2;\n"
"		pom0 += tmat * ee0_2;\n"
"		tmat = 0 * (*CUDA_LCC).Blmat[1][3] + 0 * (*CUDA_LCC).Blmat[2][3] + 0 * (*CUDA_LCC).Blmat[3][3];\n"
"		(*CUDA_LCC).de[jp][3][3] = pom + tmat * ee_3;\n"
"		(*CUDA_LCC).de0[jp][3][3] = pom0 + tmat * ee0_3;\n"
"	}\n"
"\n"
"	barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);  //__syncthreads();\n"
"}\n"
"\n"
"void bright(\n"
"	__global struct mfreq_context* CUDA_LCC,\n"
"	__global struct freq_context* CUDA_CC,\n"
"	__global double* cg,\n"
"	int jp,\n"
"	int Lpoints1,\n"
"	int Inrel)\n"
"{\n"
"	double cl, cls, dnom, s, Scale;\n"
"	double e_1, e_2, e_3, e0_1, e0_2, e0_3, de[4][4], de0[4][4];\n"
"	int ncoef0, ncoef, i, j, incl_count = 0;\n"
"\n"
"	int3 blockIdx, threadIdx;\n"
"	blockIdx.x = get_group_id(0);\n"
"	threadIdx.x = get_local_id(0);\n"
"\n"
"	//if (threadIdx.x == 0)\n"
"	//printf(\"[%3d] jp[%3d] dytemp[315]: %10.7f\\n\", blockIdx.x, jp, (*CUDA_LCC).dytemp[315]);\n"
"\n"
"	ncoef0 = (*CUDA_CC).Ncoef0;//ncoef - 2 - CUDA_Nphpar;\n"
"	ncoef = (*CUDA_CC).ma;\n"
"	cl = exp(cg[ncoef - 1]); /* Lambert */\n"
"	cls = cg[ncoef];       /* Lommel-Seeliger */\n"
"\n"
"	//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"	//{\n"
"	//	printf(\"cg[%d]: %10.7f, cg[%d]: %10.7f\\n\", ncoef - 1, cg[ncoef - 1], ncoef, cg[ncoef]);\n"
"	//	printf(\"cl: %10.7f, cls: %10.7f\\n\", cl, cls);\n"
"	//}\n"
"\n"
"	/* matrix from neo */\n"
"	/* derivatives */\n"
"\n"
"	e_1 = (*CUDA_LCC).e_1[jp];\n"
"	e_2 = (*CUDA_LCC).e_2[jp];\n"
"	e_3 = (*CUDA_LCC).e_3[jp];\n"
"	e0_1 = (*CUDA_LCC).e0_1[jp];\n"
"	e0_2 = (*CUDA_LCC).e0_2[jp];\n"
"	e0_3 = (*CUDA_LCC).e0_3[jp];\n"
"	de[1][1] = (*CUDA_LCC).de[jp][1][1];\n"
"	de[1][2] = (*CUDA_LCC).de[jp][1][2];\n"
"	de[1][3] = (*CUDA_LCC).de[jp][1][3];\n"
"	de[2][1] = (*CUDA_LCC).de[jp][2][1];\n"
"	de[2][2] = (*CUDA_LCC).de[jp][2][2];\n"
"	de[2][3] = (*CUDA_LCC).de[jp][2][3];\n"
"	de[3][1] = (*CUDA_LCC).de[jp][3][1];\n"
"	de[3][2] = (*CUDA_LCC).de[jp][3][2];\n"
"	de[3][3] = (*CUDA_LCC).de[jp][3][3];\n"
"	de0[1][1] = (*CUDA_LCC).de0[jp][1][1];\n"
"	de0[1][2] = (*CUDA_LCC).de0[jp][1][2];\n"
"	de0[1][3] = (*CUDA_LCC).de0[jp][1][3];\n"
"	de0[2][1] = (*CUDA_LCC).de0[jp][2][1];\n"
"	de0[2][2] = (*CUDA_LCC).de0[jp][2][2];\n"
"	de0[2][3] = (*CUDA_LCC).de0[jp][2][3];\n"
"	de0[3][1] = (*CUDA_LCC).de0[jp][3][1];\n"
"	de0[3][2] = (*CUDA_LCC).de0[jp][3][2];\n"
"	de0[3][3] = (*CUDA_LCC).de0[jp][3][3];\n"
"\n"
"	//if (blockIdx.x == 0 && threadIdx.x == 0) //blockIdx.x == 0 &&\n"
"	//{\n"
"	//	printf(\"[%d] jp[%3d] %10.7f, %10.7f, %10.7f, %10.7f, %10.7f, %10.7f\\n\", blockIdx.x, jp, e_1, e_2, e_3, e0_1, e0_2, e0_3);\n"
"\n"
"	//}\n"
"	//	printf(\"[%d] jp[%3d] de11: %10.7f, de12: %10.7f, de13: %10.7f\\n\", blockIdx.x, jp, de[1][1], de[1][2], de[1][3]);\n"
"		//printf(\"[%d] jp[%3d] e_1: %10.7f, e_2: %10.7f, e_3: %10.7f\\n\", blockIdx.x, jp, e_1, e_2, e_3);\n"
"\n"
"	//	printf(\"[%3d] de0[3][3]: %10.7f\\n\", threadIdx.x, de[3][3]);\n"
"		//printf(\"[%3d] jp[%d] e_1: %10.7f,\\te_2: %10.7f,\\te_3: %10.7f\\n\", threadIdx.x, jp, e_1, e_2, e_3);\n"
"\n"
"	/* Directions (and ders.) in the rotating system */\n"
"\n"
"	//\n"
"	/*Integrated brightness (phase coeff. used later) */\n"
"	double lmu, lmu0, dsmu, dsmu0, sum1, sum10, sum2, sum20, sum3, sum30;\n"
"	double br, ar, tmp1, tmp2, tmp3, tmp4, tmp5;\n"
"	//   short int *incl=&(*CUDA_LCC).incl[threadIdx.x*MAX_N_FAC];\n"
"	//   double *dbr=&(*CUDA_LCC).dbr[threadIdx.x*MAX_N_FAC];\n"
"	short int incl[MAX_N_FAC];\n"
"	double dbr[MAX_N_FAC];\n"
"	//int2 bfr;\n"
"\n"
"	br = 0;\n"
"	tmp1 = 0;\n"
"	tmp2 = 0;\n"
"	tmp3 = 0;\n"
"	tmp4 = 0;\n"
"	tmp5 = 0;\n"
"\n"
"	//j = blockIdx.x * (CUDA_Numfac1)+1; // j = 1, 290, 579 etc.\n"
"	j = 1;\n"
"	for (i = 1; i <= (*CUDA_CC).Numfac; i++, j++)\n"
"	{\n"
"		lmu = e_1 * (*CUDA_CC).Nor[i][0] + e_2 * (*CUDA_CC).Nor[i][1] + e_3 * (*CUDA_CC).Nor[i][2];\n"
"		lmu0 = e0_1 * (*CUDA_CC).Nor[i][0] + e0_2 * (*CUDA_CC).Nor[i][1] + e0_3 * (*CUDA_CC).Nor[i][2];\n"
"\n"
"		//if (blockIdx.x == 0 && threadIdx.x == 0 && i == 1) //blockIdx.x == 0 &&\n"
"		//	printf(\"[%d] jp[%3d] i[%3d] Nor[%d][0]: %10.7f, Nor[%d][1]: %10.7f, Nor[%d][2]: %10.7f\\n\",\n"
"		//		blockIdx.x, jp, i, (*CUDA_CC).Nor[i][0], i,  (*CUDA_CC).Nor[i][1], i, (*CUDA_CC).Nor[i][2]);\n"
"			//printf(\"[%d] jp[%3d] i[%3d] lmu: %10.7f, lmu0: %10.7f\\n\", blockIdx.x, jp, i, lmu, lmu0);\n"
"\n"
"		if ((lmu > TINY) && (lmu0 > TINY))\n"
"		{\n"
"			dnom = lmu + lmu0;\n"
"			s = lmu * lmu0 * (cl + cls / dnom);\n"
"			//bfr=tex1Dfetch(texArea,j);\n"
"			//ar=__hiloint2double(bfr.y,bfr.x);\n"
"\n"
"			ar = (*CUDA_LCC).Area[j];\n"
"			//if (blockIdx.x == 0 && threadIdx.x == 1) //blockIdx.x == 0 &&\n"
"			//	printf(\"[%d] s: %10.7f, Area[%3d]: %.7f (j: %5d)\\n\", blockIdx.x, s, i, ar, j);\n"
"\n"
"			br += ar * s;\n"
"			//\n"
"			incl[incl_count] = i;\n"
"			dbr[incl_count] = (*CUDA_CC).Darea[i] * s;\n"
"			incl_count++;\n"
"			//\n"
"			//double dnom_lmu0 = (lmu0 / dnom); // *(lmu0 / dnom);\n"
"			//double dnom_lmu = (lmu / dnom); // *(lmu / dnom);\n"
"			//dsmu = cls * pow(dnom_lmu0, 2.0) + cl * lmu0;\n"
"			//dsmu0 = cls * pow(dnom_lmu, 2.0) + cl * lmu;\n"
"\n"
"			//dsmu = cls * pow(lmu0 / dnom, 2.0) + cl * lmu0;\n"
"			//dsmu0 = cls * pow(lmu / dnom, 2.0) + cl * lmu;\n"
"\n"
"			double lmu0_dnom = lmu0 / dnom;\n"
"			dsmu = cls * (lmu0_dnom * lmu0_dnom) + cl * lmu0;\n"
"			double lmu_dnom = lmu / dnom;\n"
"			dsmu0 = cls * (lmu_dnom * lmu_dnom) + cl * lmu;\n"
"\n"
"\n"
"			sum1 = (*CUDA_CC).Nor[i][0] * de[1][1] + (*CUDA_CC).Nor[i][1] * de[2][1] + (*CUDA_CC).Nor[i][2] * de[3][1];\n"
"			//if (threadIdx.x == 0 && i == 1)\n"
"			//	printf(\"[%d][%3d]jp[%3d] Nor[%d][0]: %10.7f, Nor[%d][1]: %10.7f, Nor[%d][2]: %10.7f, sum1: %10.7f\\n\",\n"
"			//		blockIdx.x, threadIdx.x, jp, i, CUDA_Nor[i][0], i, CUDA_Nor[i][1], i, CUDA_Nor[i][2], sum1);\n"
"\n"
"			sum10 = (*CUDA_CC).Nor[i][0] * de0[1][1] + (*CUDA_CC).Nor[i][1] * de0[2][1] + (*CUDA_CC).Nor[i][2] * de0[3][1];\n"
"			tmp1 += ar * (dsmu * sum1 + dsmu0 * sum10);\n"
"			sum2 = (*CUDA_CC).Nor[i][0] * de[1][2] + (*CUDA_CC).Nor[i][1] * de[2][2] + (*CUDA_CC).Nor[i][2] * de[3][2];\n"
"			sum20 = (*CUDA_CC).Nor[i][0] * de0[1][2] + (*CUDA_CC).Nor[i][1] * de0[2][2] + (*CUDA_CC).Nor[i][2] * de0[3][2];\n"
"			tmp2 += ar * (dsmu * sum2 + dsmu0 * sum20);\n"
"			sum3 = (*CUDA_CC).Nor[i][0] * de[1][3] + (*CUDA_CC).Nor[i][1] * de[2][3] + (*CUDA_CC).Nor[i][2] * de[3][3];\n"
"			sum30 = (*CUDA_CC).Nor[i][0] * de0[1][3] + (*CUDA_CC).Nor[i][1] * de0[2][3] + (*CUDA_CC).Nor[i][2] * de0[3][3];\n"
"			tmp3 += ar * (dsmu * sum3 + dsmu0 * sum30);\n"
"\n"
"			//if (blockIdx.x == 9 && threadIdx.x == 10 && i <= 10)\n"
"			//	printf(\"[%d][%3d]jp[%3d] i[%4d] tmp1: %10.7f, tmp2: %10.7f, tmp3: %10.7f\\n\", blockIdx.x, threadIdx.x, jp, i, tmp1, tmp2, tmp3);\n"
"				//printf(\"[%d][%3d]jp[%3d] sum1: %10.7f, sum2: %10.7f, sum3: %10.7f\\n\", blockIdx.x, threadIdx.x, jp, sum1, sum2, sum3);\n"
"\n"
"			tmp4 += lmu * lmu0 * ar;\n"
"			tmp5 += ar * lmu * lmu0 / (lmu + lmu0);\n"
"		}\n"
"	}\n"
"\n"
"	Scale = (*CUDA_LCC).jp_Scale[jp];\n"
"	i = jp + (ncoef0 - 3 + 1) * Lpoints1;\n"
"	/* Ders. of brightness w.r.t. rotation parameters */\n"
"	(*CUDA_LCC).dytemp[i] = Scale * tmp1;\n"
"\n"
"	//if (threadIdx.x == 0) //blockIdx.x == 0 &&\n"
"	//	printf(\"[%3d] jp[%3d] Scale: %10.7f, tmp1: %10.7f, dytemp[%5d]: %10.7f\\n\", blockIdx.x, jp, Scale, tmp1, i, (*CUDA_LCC).dytemp[i]);\n"
"	//	printf(\"[%3d] dytemp[%5d]: %10.7f\\n\", blockIdx.x, i, (*CUDA_LCC).dytemp[i]);\n"
"\n"
"	i += Lpoints1;\n"
"	(*CUDA_LCC).dytemp[i] = Scale * tmp2;\n"
"	i += Lpoints1;\n"
"	(*CUDA_LCC).dytemp[i] = Scale * tmp3;\n"
"\n"
"	//if (blockIdx.x == 0)\n"
"	//	printf(\"[%d][%3d][%4d] Scale: %10.7f, tmp1: %10.7f, tmp2; %10.7f, tmp3: %10.7f\\n\", blockIdx.x, threadIdx.x, jp, Scale, tmp1, tmp2, tmp3);\n"
"\n"
"	i += Lpoints1;\n"
"	/* Ders. of br. w.r.t. phase function params. */\n"
"	(*CUDA_LCC).dytemp[i] = br * (*CUDA_LCC).jp_dphp_1[jp];\n"
"	i += Lpoints1;\n"
"	(*CUDA_LCC).dytemp[i] = br * (*CUDA_LCC).jp_dphp_2[jp];\n"
"	i += Lpoints1;\n"
"	(*CUDA_LCC).dytemp[i] = br * (*CUDA_LCC).jp_dphp_3[jp];\n"
"\n"
"	/* Ders. of br. w.r.t. cl, cls */\n"
"	(*CUDA_LCC).dytemp[jp + (ncoef - 1) * (Lpoints1)] = Scale * tmp4 * cl;\n"
"	(*CUDA_LCC).dytemp[jp + (ncoef) * (Lpoints1)] = Scale * tmp5;\n"
"\n"
"	/* Scaled brightness */\n"
"	(*CUDA_LCC).ytemp[jp] = br * Scale;\n"
"\n"
"	//if (blockIdx.x == 0 && threadIdx.x == 0) //blockIdx.x == 0 &&\n"
"	//	printf(\"[%d][%d] br: %10.7f, Scale: %10.7f, ytemp[%d]: %10.6f\\n\", blockIdx.x, threadIdx.x, br, Scale, jp, (*CUDA_LCC).ytemp[jp]);\n"
"\n"
"	ncoef0 -= 3;\n"
"	int m, m1, mr, iStart;\n"
"	int d, d1, dr;\n"
"	if (Inrel)\n"
"	{\n"
"		iStart = 2;\n"
"		//m = blockIdx.x * CUDA_Dg_block + 2 * (CUDA_Numfac1);\n"
"		m = 2 * (*CUDA_CC).Numfac1;\n"
"		d = jp + 2 * (Lpoints1);\n"
"	}\n"
"	else\n"
"	{\n"
"		iStart = 1;\n"
"		//m = blockIdx.x * CUDA_Dg_block + (CUDA_Numfac1);\n"
"		m = (*CUDA_CC).Numfac1;\n"
"		d = jp + (Lpoints1);\n"
"	}\n"
"\n"
"\n"
"	m1 = m + (*CUDA_CC).Numfac1;\n"
"	mr = 2 * (*CUDA_CC).Numfac1;\n"
"	d1 = d + Lpoints1;\n"
"	dr = 2 * Lpoints1;\n"
"\n"
"	//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"	//	printf(\"m: %d, m1: %d, Dg_block: %d, Numfac1: %d\\n\", m, m1, CUDA_Dg_block, CUDA_Numfac1);\n"
"\n"
"	/* Derivatives of brightness w.r.t. g-coeffs */\n"
"	if (incl_count)\n"
"	{\n"
"		for (i = iStart; i <= ncoef0; i += 2, m += mr, m1 += mr, d += dr, d1 += dr)\n"
"		{\n"
"			double tmp = 0, tmp1 = 0;\n"
"\n"
"			double l_dbr = dbr[0];\n"
"			int l_incl = incl[0];\n"
"\n"
"			//int2 xx;\n"
"			//xx=tex1Dfetch(texDg,m+l_incl);\n"
"			//tmp = l_dbr * __hiloint2double(xx.y,xx.x);\n"
"			tmp = l_dbr * (*CUDA_LCC).Dg[m + l_incl];\n"
"\n"
"			//if (blockIdx.x == 0 && threadIdx.x == 0 && i < 10)\n"
"			//	printf(\"[%d] jp[%3d] i[%2d] l_dbr: %10.7f, Dg[%5d]: %10.7f\\n\", blockIdx.x, jp, i, l_dbr, m + l_incl, (*CUDA_LCC).Dg[m + l_incl]);\n"
"\n"
"			if ((i + 1) <= ncoef0)\n"
"			{\n"
"				//xx=tex1Dfetch(texDg,m1+l_incl);\n"
"				//tmp1 = l_dbr * __hiloint2double(xx.y,xx.x);\n"
"				tmp1 = l_dbr * (*CUDA_LCC).Dg[m1 + l_incl];\n"
"			}\n"
"\n"
"			for (j = 1; j < incl_count; j++)\n"
"			{\n"
"				double l_dbr = dbr[j];\n"
"				int l_incl = incl[j];\n"
"\n"
"				//int2 xx;\n"
"				//xx=tex1Dfetch(texDg,m+l_incl);\n"
"				//tmp += l_dbr * __hiloint2double(xx.y,xx.x);\n"
"				tmp += l_dbr * (*CUDA_LCC).Dg[m + l_incl];\n"
"				if ((i + 1) <= ncoef0)\n"
"				{\n"
"					//xx=tex1Dfetch(texDg,m1+l_incl);\n"
"					//tmp1 += l_dbr * __hiloint2double(xx.y,xx.x);\n"
"					tmp1 += l_dbr * (*CUDA_LCC).Dg[m1 + l_incl];\n"
"				}\n"
"			}\n"
"\n"
"			(*CUDA_LCC).dytemp[d] = Scale * tmp;\n"
"\n"
"			//>>>>>>>>>\n"
"			// Check for these values at this point on first pass if any anomalies were suspected within results:\n"
"			//\n"
"			//[  4] jp[  1] i[  2] Scale:  0.8508436, tmp:  1.3356285, dytemp[  315]:  1.1364109\n"
"			//[  5] jp[  1] i[  2] Scale:  0.8508436, tmp:  1.3368231, dytemp[  315]:  1.1374274\n"
"			//[  2] jp[  1] i[  2] Scale:  0.8508436, tmp:  1.3322120, dytemp[  315]:  1.1335041\n"
"			//[  3] jp[  1] i[  2] Scale:  0.8508436, tmp:  1.3341985, dytemp[  315]:  1.1351942\n"
"			//[  9] jp[  1] i[  2] Scale:  0.8508436, tmp:  1.3412586, dytemp[  315]:  1.1412013\n"
"			//[  7] jp[  1] i[  2] Scale:  0.8508436, tmp:  1.3400172, dytemp[  315]:  1.1401451\n"
"			//[  8] jp[  1] i[  2] Scale:  0.8508436, tmp:  1.3400477, dytemp[  315]:  1.1401710\n"
"			//[  1] jp[  1] i[  2] Scale:  0.8508436, tmp:  1.3339482, dytemp[  315]:  1.1349812\n"
"			//[  6] jp[  1] i[  2] Scale:  0.8508436, tmp:  1.3382762, dytemp[  315]:  1.1386637\n"
"			//[  0] jp[  1] i[  2] Scale:  0.8508436, tmp:  1.3369873, dytemp[  315]:  1.1375671\n"
"			//\n"
"			//\n"
"			//if (threadIdx.x == 0 && jp == 1 && i == 2)\n"
"			//	printf(\"[%3d] jp[%3d] i[%3d] Scale: %10.7f, tmp: %10.7f, dytemp[%5d]: %10.7f\\n\", blockIdx.x, jp, i, Scale, tmp, d, (*CUDA_LCC).dytemp[d]);\n"
"\n"
"			//if (threadIdx.x == 0 && i == 2)\n"
"			//	printf(\"[%3d] jp[%3d] i[%3d] Scale: %10.7f, tmp: %10.7f, dytemp[%5d]: %10.7f\\n\", blockIdx.x, jp, i, Scale, tmp, d, (*CUDA_LCC).dytemp[d]);\n"
"\n"
"			//>>>>>>>>> dytemp [315]\n"
"\n"
"			if ((i + 1) <= ncoef0)\n"
"			{\n"
"				(*CUDA_LCC).dytemp[d1] = Scale * tmp1;\n"
"\n"
"				//if (threadIdx.x == 0 && jp == 1)\n"
"				//	printf(\"[%3d] jp[%3d] i[%3d] Scale: %10.7f, tmp1: %10.7f, dytemp[%5d]: %10.7f\\n\", blockIdx.x, jp, i, Scale, tmp1, d1, (*CUDA_LCC).dytemp[d1]);\n"
"			}\n"
"		}\n"
"	}\n"
"	else\n"
"	{\n"
"		for (i = 1; i <= ncoef0; i++, d += Lpoints1)\n"
"			(*CUDA_LCC).dytemp[d] = 0;\n"
"	}\n"
"\n"
"	//return(0);\n"
"}\n"
"//Convexity regularization function\n"
"\n"
"//  8.11.2006\n"
"\n"
"\n"
"double conv(\n"
"	__global struct mfreq_context* CUDA_LCC,\n"
"	__global struct freq_context* CUDA_CC,\n"
"	__local double* res,\n"
"	int nc,\n"
"	int tmpl,\n"
"	int tmph,\n"
"	int brtmpl,\n"
"	int brtmph)\n"
"{\n"
"	int i, j, k;\n"
"	double tmp = 0.0;\n"
"	double dtmp;\n"
"	int3 threadIdx, blockIdx;\n"
"	threadIdx.x = get_local_id(0);\n"
"	blockIdx.x = get_group_id(0);\n"
"\n"
"	//j = blockIdx.x * (CUDA_Numfac1)+brtmpl;\n"
"	j = brtmpl;\n"
"	for (i = brtmpl; i <= brtmph; i++, j++)\n"
"	{\n"
"		//tmp += CUDA_Area[j] * CUDA_Nor[i][nc];\n"
"		tmp += (*CUDA_LCC).Area[j] * (*CUDA_CC).Nor[i][nc];\n"
"	}\n"
"\n"
"	res[threadIdx.x] = tmp;\n"
"\n"
"	//if (threadIdx.x == 0)\n"
"	//    printf(\"conv>>> [%d] jp-1[%3d] res[%3d]: %10.7f\\n\", blockIdx.x, nc, threadIdx.x, res[threadIdx.x]);\n"
"\n"
"	barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"\n"
"	//parallel reduction\n"
"	k = BLOCK_DIM >> 1;\n"
"	while (k > 1)\n"
"	{\n"
"		if (threadIdx.x < k)\n"
"			res[threadIdx.x] += res[threadIdx.x + k];\n"
"		k = k >> 1;\n"
"		barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"	}\n"
"\n"
"	if (threadIdx.x == 0)\n"
"	{\n"
"		tmp = res[0] + res[1];\n"
"	}\n"
"	//parallel reduction end\n"
"	barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"\n"
"	//int m = blockIdx.x * (*CUDA_CC).Dg_block + tmpl * (*CUDA_CC).Numfac1);   // <<<<<<<<<<<<<<<<<<<<<<<<<<<<< !!!\n"
"	int m = tmpl * (*CUDA_CC).Numfac1;\n"
"	for (j = tmpl; j <= tmph; j++)  //, m += (*CUDA_CC).Numfac1)\n"
"	{\n"
"		// printf(\"m: %4d\\n\", m);\n"
"		dtmp = 0;\n"
"		if (j <= (*CUDA_CC).Ncoef)\n"
"		{\n"
"			int mm = m + 1;\n"
"			for (i = 1; i <= (*CUDA_CC).Numfac; i++, mm++)\n"
"			{\n"
"				// dtmp += CUDA_Darea[i] * CUDA_Dg[mm] * CUDA_Nor[i][nc];\n"
"				dtmp += (*CUDA_CC).Darea[i] * (*CUDA_LCC).Dg[mm] * (*CUDA_CC).Nor[i][nc];\n"
"\n"
"				//if (blockIdx.x == 0 && j == 8)\n"
"				//	printf(\"[%d][%3d]  Darea[%4d]: %.7f, Dg[%4d]: %.7f, Nor[%3d][%3d]: %10.7f\\n\",\n"
"				//		blockIdx.x, threadIdx.x, i, (*CUDA_CC).Darea[i], mm, (*CUDA_LCC).Dg[mm], i, nc, (*CUDA_CC).Nor[i][nc]);\n"
"			}\n"
"		}\n"
"\n"
"		(*CUDA_LCC).dyda[j] = dtmp;\n"
"\n"
"		//if (blockIdx.x == 0) // && threadIdx.x == 1)\n"
"		//    printf(\"[mrqcof_curve1_last -> conv] [%d][%3d] jp - 1: %3d, j[%3d] dyda[%3d]: %10.7f\\n\",\n"
"		//        blockIdx.x, threadIdx.x, nc, j, j, (*CUDA_LCC).dyda[j]);\n"
"	}\n"
"	barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"\n"
"	return (tmp);\n"
"}\n"
" //slighly changed code from Numerical Recipes\n"
" //  converted from Mikko\'s fortran code\n"
"\n"
" //  8.11.2006\n"
"\n"
"\n"
"//#include <stdio.h>\n"
"//#include <stdlib.h>\n"
"//#include \"globals_CUDA.h\"\n"
"//#include \"declarations_CUDA.h\"\n"
"\n"
"\n"
"/* comment the following line if no YORP */\n"
"/*#define YORP*/\n"
"\n"
"void mrqcof_start(\n"
"	__global struct mfreq_context* CUDA_LCC,\n"
"	__global struct freq_context* CUDA_CC,\n"
"	__global double* cg,\n"
"	__global double* alpha,\n"
"	__global double* beta)\n"
"{\n"
"	int3 threadIdx, blockIdx;\n"
"	threadIdx.x = get_local_id(0);\n"
"	blockIdx.x = get_group_id(0);\n"
"	int x = threadIdx.x;\n"
"\n"
"	int brtmph, brtmpl;\n"
"	// brtmph = 288 / 128 = 2 (2.25)\n"
"	brtmph = (*CUDA_CC).Numfac / BLOCK_DIM;\n"
"	if ((*CUDA_CC).Numfac % BLOCK_DIM)\n"
"	{\n"
"		brtmph++; // brtmph = 3\n"
"	}\n"
"\n"
"	brtmpl = threadIdx.x * brtmph;	// 0 * 3 = 0, 1 * 3 = 3, 6,  9, 12, 15, 18... 381(127 * 3)\n"
"	brtmph = brtmpl + brtmph;		//		   3,         6, 9, 12, 15, 18, 21... 384(381 + 3)\n"
"	if (brtmph > (*CUDA_CC).Numfac) //  97 * 3 = 201 > 288\n"
"	{\n"
"		brtmph = (*CUDA_CC).Numfac; // 3, 6, ... max 288\n"
"	}\n"
"\n"
"	brtmpl++; // 1..382\n"
"	//if(blockIdx.x == 0)\n"
"	//	printf(\"Idx: %d | Numfac: %d | brtmpl: %d | brtmph: %d\\n\", threadIdx.x, (*CUDA_CC).Numfac, brtmpl, brtmph);\n"
"\n"
"		/*  ---   CURV  ---  */\n"
"	curv(CUDA_LCC, CUDA_CC, cg, brtmpl, brtmph);\n"
"\n"
"	if (threadIdx.x == 0)\n"
"	{\n"
"		//   #ifdef YORP\n"
"		//      blmatrix(a[ma-5-Nphpar],a[ma-4-Nphpar]);\n"
"		  // #else\n"
"\n"
"		//if (blockIdx.x == 0)\n"
"		//	printf(\"[mrqcof_start] a[%3d]: %10.7f, a[%3d]: %10.7f\\n\",\n"
"		//		(*CUDA_CC).ma - 4 - (*CUDA_CC).Nphpar, cg[(*CUDA_CC).ma - 4 - (*CUDA_CC).Nphpar],\n"
"		//		(*CUDA_CC).ma - 3 - (*CUDA_CC).Nphpar, cg[(*CUDA_CC).ma - 3 - (*CUDA_CC).Nphpar]);\n"
"\n"
"		  /*  ---  BLMATRIX ---  */\n"
"		blmatrix(CUDA_LCC, cg[(*CUDA_CC).ma - 4 - (*CUDA_CC).Nphpar], cg[(*CUDA_CC).ma - 3 - (*CUDA_CC).Nphpar]);\n"
"		//   #endif\n"
"		(*CUDA_LCC).trial_chisq = 0.0;\n"
"		(*CUDA_LCC).np = 0;\n"
"		(*CUDA_LCC).np1 = 0;\n"
"		(*CUDA_LCC).np2 = 0;\n"
"		(*CUDA_LCC).ave = 0;\n"
"	}\n"
"\n"
"	brtmph = (*CUDA_CC).Mfit / BLOCK_DIM;\n"
"	if ((*CUDA_CC).Mfit % BLOCK_DIM) brtmph++;\n"
"	brtmpl = threadIdx.x * brtmph;\n"
"	brtmph = brtmpl + brtmph;\n"
"	if (brtmph > (*CUDA_CC).Mfit) brtmph = (*CUDA_CC).Mfit;\n"
"	brtmpl++;\n"
"\n"
"	__private int idx, k, j;\n"
"\n"
"	for (j = brtmpl; j <= brtmph; j++)\n"
"	{\n"
"		for (k = 1; k <= j; k++)\n"
"		{\n"
"			idx = j * (*CUDA_CC).Mfit1 + k;\n"
"			alpha[idx] = 0;\n"
"			//if (blockIdx.x == 0 && j < 3)\n"
"			//	printf(\"[%3d] j: %d, k: %d, Mfit1: %2d, alpha[%3d]: %.7f\\n\", threadIdx.x, j, k, (*CUDA_CC).Mfit1, idx, alpha[idx]);\n"
"		}\n"
"		beta[j] = 0;\n"
"	}\n"
"\n"
"	barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads(); //pro jistotu\n"
"\n"
"	//int q = (*CUDA_CC).Ncoef0 + 2;\n"
"	//if (blockIdx.x == 0)\n"
"	//	printf(\"[neo] [%d][%3d] cg[%3d]: %10.7f\\n\", blockIdx.x, threadIdx.x, q, (*CUDA_LCC).cg[q]);\n"
"\n"
"\n"
"}\n"
"\n"
"void mrqcof_matrix(\n"
"	__global struct mfreq_context* CUDA_LCC,\n"
"	__global struct freq_context* CUDA_CC,\n"
"	__global double* cg,\n"
"	int Lpoints,\n"
"	int num)\n"
"{\n"
"	matrix_neo(CUDA_LCC, CUDA_CC, cg, (*CUDA_LCC).np, Lpoints, num);\n"
"}\n"
"\n"
"void mrqcof_curve1(\n"
"	__global struct mfreq_context* CUDA_LCC,\n"
"	__global struct freq_context* CUDA_CC,\n"
"	__global double* cg,\n"
"	__local double* tmave,\n"
"	int Inrel,\n"
"	int Lpoints,\n"
"	int num)\n"
"{\n"
"	//__local double tmave[BLOCK_DIM];  // __shared__\n"
"	__private int Lpoints1 = Lpoints + 1;\n"
"	__private int k, lnp, jp;\n"
"	__private double lave;\n"
"\n"
"	lnp = (*CUDA_LCC).np;\n"
"	lave = (*CUDA_LCC).ave;\n"
"\n"
"	int3 blockIdx, threadIdx;\n"
"	threadIdx.x = get_local_id(0);\n"
"	blockIdx.x = get_group_id(0);\n"
"\n"
"	//precalc thread boundaries\n"
"	int brtmph, brtmpl;\n"
"	brtmph = Lpoints / BLOCK_DIM;\n"
"	if (Lpoints % BLOCK_DIM) brtmph++;\n"
"	brtmpl = threadIdx.x * brtmph;\n"
"	brtmph = brtmpl + brtmph;\n"
"	if (brtmph > Lpoints) brtmph = Lpoints;\n"
"	brtmpl++;\n"
"\n"
"	for (jp = brtmpl; jp <= brtmph; jp++)\n"
"	{\n"
"		//if (num == 1 && blockIdx.x == 2)\n"
"		//	printf(\"[%d][%d] jp: %d\\n\", blockIdx.x, threadIdx.x, jp);\n"
"			//if (blockIdx.x == 0)\n"
"			//	printf(\"[%3d][%3d] brtmpl: %3d, brtmph: %3d\\n\", blockIdx.x, threadIdx.x, brtmpl, brtmph);\n"
"\n"
"		//if (blockIdx.x == 0 && (jp == 127 || jp == 130))\n"
"		//	printf(\"jp[%d] dytemp[8636]: %10.7f\\n\", jp, dytemp[8636]);\n"
"\n"
"			/*  ---  BRIGHT  ---  */\n"
"		bright(CUDA_LCC, CUDA_CC, cg, jp, Lpoints1, Inrel);\n"
"	}\n"
"\n"
"	barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"\n"
"	if (Inrel == 1)\n"
"	{\n"
"		int tmph, tmpl;\n"
"		tmph = (*CUDA_CC).ma / BLOCK_DIM;\n"
"		if ((*CUDA_CC).ma % BLOCK_DIM) tmph++;\n"
"		tmpl = threadIdx.x * tmph;\n"
"		tmph = tmpl + tmph;\n"
"		if (tmph > (*CUDA_CC).ma) tmph = (*CUDA_CC).ma;\n"
"		tmpl++;\n"
"		if (tmpl == 1) tmpl++;\n"
"\n"
"		int ixx;\n"
"		ixx = tmpl * Lpoints1;\n"
"\n"
"		for (int l = tmpl; l <= tmph; l++)\n"
"		{\n"
"			//jp==1\n"
"			ixx++;\n"
"			//(*CUDA_LCC).dave[l] = (*CUDA_LCC).dytemp[ixx];\n"
"			(*CUDA_LCC).dave[l] = (*CUDA_LCC).dytemp[ixx];\n"
"\n"
"			// dytemp[315] -> OK\n"
"			//if (threadIdx.x == 1)\n"
"			//	printf(\"[Device | mrqcof_curv1] [%3d] dytemp[%3d]: %10.7f, dave[%3d]: %10.7f\\n\", blockIdx.x, ixx, (*CUDA_LCC).dytemp[ixx], l, (*CUDA_LCC).dave[l]);\n"
"\n"
"			//jp>=2\n"
"			ixx++;\n"
"			for (int jp = 2; jp <= Lpoints; jp++, ixx++)\n"
"			{\n"
"				//(*CUDA_LCC).dave[l] = (*CUDA_LCC).dave[l] + (*CUDA_LCC).dytemp[ixx];\n"
"				(*CUDA_LCC).dave[l] = (*CUDA_LCC).dave[l] + (*CUDA_LCC).dytemp[ixx];\n"
"\n"
"				//if (threadIdx.x == 1)\n"
"				//	printf(\"[Device | mrqcof_curv1] [%3d] dytemp[%3d]: %10.7f, dave[%3d]: %10.7f\\n\", blockIdx.x, ixx, (*CUDA_LCC).dytemp[ixx], l, (*CUDA_LCC).dave[l]);\n"
"			}\n"
"		}\n"
"\n"
"		tmave[threadIdx.x] = 0;\n"
"		for (int jp = brtmpl; jp <= brtmph; jp++)\n"
"		{\n"
"			tmave[threadIdx.x] += (*CUDA_LCC).ytemp[jp];\n"
"\n"
"			//if (threadIdx.x == 0) //blockIdx.x == 1 &&\n"
"			//	printf(\"[%d][%3d] ytemp[%d]: %10.7f, tmave[%3d]: %10.7f\\n\", blockIdx.x, threadIdx.x, jp, (*CUDA_LCC).ytemp[jp], threadIdx.x, tmave[threadIdx.x]);\n"
"		}\n"
"\n"
"		barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"\n"
"		//parallel reduction\n"
"		k = BLOCK_DIM >> 1;\n"
"		while (k > 1)\n"
"		{\n"
"			if (threadIdx.x < k) tmave[threadIdx.x] += tmave[threadIdx.x + k];\n"
"			k = k >> 1;\n"
"			barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"		}\n"
"\n"
"		if (threadIdx.x == 0)\n"
"		{\n"
"			lave = tmave[0] + tmave[1];\n"
"\n"
"			//if (blockIdx.x == 2 && num == 1)\n"
"			 //   printf(\"[%d][%d]  \\tlave: % .6f\\n\", blockIdx.x, threadIdx.x, lave);\n"
"		}\n"
"		//parallel reduction end\n"
"	}\n"
"	if (threadIdx.x == 0)\n"
"	{\n"
"		(*CUDA_LCC).np = lnp + Lpoints;\n"
"		(*CUDA_LCC).ave = lave;\n"
"	}\n"
"}\n"
"\n"
"void mrqcof_curve1_last(\n"
"	__global struct mfreq_context* CUDA_LCC,\n"
"	__global struct freq_context* CUDA_CC,\n"
"	__global double* a,\n"
"	__global double* alpha,\n"
"	__global double* beta,\n"
"	__local double* res,\n"
"	int Inrel,\n"
"	int Lpoints)\n"
"{\n"
"	int l, jp, lnp;\n"
"	double ymod, lave;\n"
"	int3 threadIdx, blockIdx;\n"
"	threadIdx.x = get_local_id(0);\n"
"	blockIdx.x = get_group_id(0);\n"
"\n"
"	lnp = (*CUDA_LCC).np;\n"
"	//\n"
"	if (threadIdx.x == 0)\n"
"	{\n"
"		if (Inrel == 1) /* is the LC relative? */\n"
"		{\n"
"			lave = 0;\n"
"			for (l = 1; l <= (*CUDA_CC).ma; l++)\n"
"				(*CUDA_LCC).dave[l] = 0;\n"
"		}\n"
"		else\n"
"			lave = (*CUDA_LCC).ave;\n"
"	}\n"
"	//precalc thread boundaries\n"
"	int tmph, tmpl;\n"
"	tmph = (*CUDA_CC).ma / BLOCK_DIM;\n"
"	if ((*CUDA_CC).ma % BLOCK_DIM) tmph++;\n"
"	tmpl = threadIdx.x * tmph;\n"
"	tmph = tmpl + tmph;\n"
"	if (tmph > (*CUDA_CC).ma) tmph = (*CUDA_CC).ma;\n"
"	tmpl++;\n"
"	//\n"
"	int brtmph, brtmpl;\n"
"	brtmph = (*CUDA_CC).Numfac / BLOCK_DIM;\n"
"	if ((*CUDA_CC).Numfac % BLOCK_DIM) brtmph++;\n"
"	brtmpl = threadIdx.x * brtmph;\n"
"	brtmph = brtmpl + brtmph;\n"
"	if (brtmph > (*CUDA_CC).Numfac) brtmph = (*CUDA_CC).Numfac;\n"
"	brtmpl++;\n"
"\n"
"	barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"	//if (threadIdx.x == 0)\n"
"	//	printf(\"conv>>> [%d] \\n\", blockIdx.x);\n"
"\n"
"	for (jp = 1; jp <= Lpoints; jp++)\n"
"	{\n"
"		lnp++;\n"
"		// *--- CONV() ---* //\n"
"		ymod = conv(CUDA_LCC, CUDA_CC, res, jp - 1, tmpl, tmph, brtmpl, brtmph);\n"
"\n"
"		if (threadIdx.x == 0)\n"
"		{\n"
"			(*CUDA_LCC).ytemp[jp] = ymod;\n"
"\n"
"			if (Inrel == 1)\n"
"				lave = lave + ymod;\n"
"		}\n"
"		for (l = tmpl; l <= tmph; l++)\n"
"		{\n"
"			//(*CUDA_LCC).dytemp[jp + l * (Lpoints + 1)] = (*CUDA_LCC).dyda[l];\n"
"			(*CUDA_LCC).dytemp[jp + l * (Lpoints + 1)] = (*CUDA_LCC).dyda[l];\n"
"\n"
"			if (Inrel == 1)\n"
"				(*CUDA_LCC).dave[l] = (*CUDA_LCC).dave[l] + (*CUDA_LCC).dyda[l];\n"
"		}\n"
"		/* save lightcurves */\n"
"		barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"\n"
"		/*         if ((*CUDA_LCC).Lastcall == 1) always ==0\n"
"					 (*CUDA_LCC).Yout[np] = ymod;*/\n"
"	} /* jp, lpoints */\n"
"\n"
"	if (threadIdx.x == 0)\n"
"	{\n"
"		(*CUDA_LCC).np = lnp;\n"
"		(*CUDA_LCC).ave = lave;\n"
"	}\n"
"}\n"
"\n"
"double mrqcof_end(\n"
"	__global struct mfreq_context* CUDA_LCC,\n"
"	__global struct freq_context* CUDA_CC,\n"
"	__global double* alpha)\n"
"{\n"
"	int j, k;\n"
"	int3 threadIdx, blockIdx;\n"
"	threadIdx.x = get_local_id(0);\n"
"	blockIdx.x = get_group_id(0);\n"
"\n"
"	for (int j = 2; j <= (*CUDA_CC).Mfit; j++)\n"
"	{\n"
"		for (k = 1; k <= j - 1; k++)\n"
"		{\n"
"			alpha[k * (*CUDA_CC).Mfit1 + j] = alpha[j * (*CUDA_CC).Mfit1 + k];\n"
"			//if (blockIdx.x ==0 && threadIdx.x == 0)\n"
"			//	printf(\"[mrqcof_end] [%d][%3d] alpha[%3d]: %10.7f\\n\", blockIdx.x, threadIdx.x, k * (*CUDA_CC).Mfit1 + j, alpha[k * (*CUDA_CC).Mfit1 + j]);\n"
"		}\n"
"	}\n"
"\n"
"	return (*CUDA_LCC).trial_chisq;\n"
"}\n"
"\n"
"//int gauss_errc(freq_context* CUDA_LCC, const int ma)\n"
"//mrqmin_1_end(CUDA_LCC, CUDA_ma, CUDA_mfit, CUDA_mfit1, block);\n"
"//int gauss_errc(struct mfreq_context* CUDA_LCC, struct freq_context* CUDA_CC, int* sh_icol, int* sh_irow, double* sh_big, int icol, double pivinv)\n"
"int gauss_errc(\n"
"	__global struct mfreq_context* CUDA_LCC,\n"
"	__global struct freq_context* CUDA_CC)\n"
"{\n"
"	//__shared__ int icol;\n"
"	//__shared__ double pivinv;\n"
"	//__shared__ int sh_icol[CUDA_BLOCK_DIM];\n"
"	//__shared__ int sh_irow[CUDA_BLOCK_DIM];\n"
"	//__shared__ double sh_big[CUDA_BLOCK_DIM];\n"
"\n"
"	double big, dum, temp;\n"
"	double tmpSwap;\n"
"	int i, licol = 0, irow = 0, j, k, l, ll;\n"
"	int n = (*CUDA_CC).Mfit; // 54\n"
"	int m = (*CUDA_CC).ma;   // 57\n"
"\n"
"	int3 threadIdx, blockIdx;\n"
"	threadIdx.x = get_local_id(0);\n"
"	blockIdx.x = get_group_id(0);\n"
"\n"
"	int brtmph, brtmpl;\n"
"	brtmph = n / BLOCK_DIM;\n"
"	if (n % BLOCK_DIM) brtmph++;		// 1 (thr 1)\n"
"	brtmpl = threadIdx.x * brtmph;		// 0\n"
"	brtmph = brtmpl + brtmph;			// 1\n"
"	if (brtmph > n) brtmph = n;			// false | 1\n"
"	brtmpl++;							// 1\n"
"\n"
"	if (threadIdx.x == 0)\n"
"	{\n"
"		for (j = 1; j <= n; j++) (*CUDA_LCC).ipiv[j] = 0;\n"
"	}\n"
"\n"
"	barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"\n"
"	//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"	//	printf(\"brtmpl: %3d, brtmph: %3d\\n\", brtmpl, brtmph);\n"
"\n"
"	for (i = 1; i <= n; i++)\n"
"	{\n"
"		big = 0;\n"
"		irow = 0;\n"
"		licol = 0;\n"
"		for (j = brtmpl; j <= brtmph; j++)  // 1 to 1 on thread 0 first pass for all \"i\"\n"
"		{\n"
"			//if (threadIdx.x == 0 && i == 2)\n"
"			//	printf(\"[%d][%3d] ipiv[%3d]: %5d, covar[%3d]: %10.7f\\n\",\n"
"			//		blockIdx.x, threadIdx.x, j, (*CUDA_LCC).ipiv[j], j * (*CUDA_CC).Mfit1 + 1, (*CUDA_LCC).covar[j * (*CUDA_CC).Mfit1 + 1]);\n"
"\n"
"			if ((*CUDA_LCC).ipiv[j] != 1)\n"
"			{\n"
"				//if (blockIdx.x == 0)\n"
"				//	printf(\"[%3d] i[%3d] ipiv[%3d]: %10.7f\\n\", threadIdx.x, i, j, (*CUDA_LCC).ipiv[j]);\n"
"\n"
"				int ixx = j * (*CUDA_CC).Mfit1 + 1;\n"
"				for (k = 1; k <= n; k++, ixx++)\n"
"				{\n"
"					if ((*CUDA_LCC).ipiv[k] == 0)\n"
"					{\n"
"						double tmpcov = fabs((*CUDA_LCC).covar[ixx]);\n"
"						if (tmpcov >= big)\n"
"						{\n"
"							//if (blockIdx.x == 0)\n"
"							//	printf(\"[%3d] i[%3d] ipiv[%3d]: %3d, ipiv[%3d]: %3d, big: %10.7f, tmpcov: %10.7f, covar[%3d]: %10.7f\\n\",\n"
"							//		threadIdx.x, i, j, (*CUDA_LCC).ipiv[j], k, (*CUDA_LCC).ipiv[k], big, tmpcov, ixx, (*CUDA_LCC).covar[ixx]);\n"
"\n"
"							big = tmpcov;\n"
"							irow = j;\n"
"							licol = k;\n"
"						}\n"
"					}\n"
"					else if ((*CUDA_LCC).ipiv[k] > 1)\n"
"					{\n"
"						//printf(\"-\");\n"
"						barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"						/*					        deallocate_vector((void *) ipiv);\n"
"												deallocate_vector((void *) indxc);\n"
"												deallocate_vector((void *) indxr);*/\n"
"						return(1);\n"
"					}\n"
"				}\n"
"			}\n"
"		}\n"
"		(*CUDA_LCC).sh_big[threadIdx.x] = big;\n"
"		(*CUDA_LCC).sh_irow[threadIdx.x] = irow;\n"
"		(*CUDA_LCC).sh_icol[threadIdx.x] = licol;\n"
"\n"
"		barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"\n"
"		//int d = (*CUDA_LCC).sh_icol[0];\n"
"		//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"		//	printf(\"[%3d][%3d] i: %3d, licol: %3d\\n\", blockIdx.x, threadIdx.x, i, licol);\n"
"		//	//printf(\"[%3d][%3d] i: %3d, sh_col[%3d]: %d, d: %3d\\n\", blockIdx.x, threadIdx.x, i, threadIdx.x, (*CUDA_LCC).sh_icol[threadIdx.x], d);\n"
"\n"
"		if (threadIdx.x == 0)\n"
"		{\n"
"			big = (*CUDA_LCC).sh_big[0];				// = 0\n"
"			(*CUDA_LCC).icol = (*CUDA_LCC).sh_icol[0];	// = 0\n"
"			irow = (*CUDA_LCC).sh_irow[0];				// = 0\n"
"\n"
"			for (j = 1; j < BLOCK_DIM; j++)				// 1..127\n"
"			{\n"
"				//if (blockIdx.x == 0 && i == 1)\n"
"				//	printf(\"sh_big[%3d]: %10.7f\\n\", j, (*CUDA_LCC).sh_big[j]);\n"
"\n"
"				if ((*CUDA_LCC).sh_big[j] >= big)\n"
"				{\n"
"					big = (*CUDA_LCC).sh_big[j];\n"
"					irow = (*CUDA_LCC).sh_irow[j];\n"
"					(*CUDA_LCC).icol = (*CUDA_LCC).sh_icol[j];\n"
"				}\n"
"			}\n"
"\n"
"			//(*CUDA_LCC).ipiv[(*CUDA_LCC).icol] = ++(*CUDA_LCC).ipiv[(*CUDA_LCC).icol];\n"
"			++(*CUDA_LCC).ipiv[(*CUDA_LCC).icol];\n"
"\n"
"			//if (blockIdx.x == 0)\n"
"			//	printf(\"i: %2d, icol: %3d, irow: %3d, ipiv[%3d]: %3d\\n\", i, (*CUDA_LCC).icol, irow, (*CUDA_LCC).icol, (*CUDA_LCC).ipiv[(*CUDA_LCC).icol]);\n"
"\n"
"\n"
"			if (irow != (*CUDA_LCC).icol) // what is going on here ???\n"
"			{\n"
"				//if (blockIdx.x == 0)\n"
"				//	printf(\"irow: %3d\\n\", irow);\n"
"				for (l = 1; l <= n; l++)\n"
"				{\n"
"					//SwapDouble((*CUDA_LCC).covar[irow * (*CUDA_CC).Mfit1 + l], (*CUDA_LCC).covar[icol * (*CUDA_CC).Mfit1 + l]);\n"
"					tmpSwap = (*CUDA_LCC).covar[irow * (*CUDA_CC).Mfit1 + l];\n"
"					(*CUDA_LCC).covar[irow * (*CUDA_CC).Mfit1 + l] = (*CUDA_LCC).covar[(*CUDA_LCC).icol * (*CUDA_CC).Mfit1 + l];\n"
"					(*CUDA_LCC).covar[(*CUDA_LCC).icol * (*CUDA_CC).Mfit1 + l] = tmpSwap;\n"
"\n"
"				}\n"
"\n"
"				//SwapDouble((*CUDA_LCC).da[irow], (*CUDA_LCC).da[icol]);\n"
"				tmpSwap = (*CUDA_LCC).da[irow];\n"
"				(*CUDA_LCC).da[irow] = (*CUDA_LCC).da[(*CUDA_LCC).icol];\n"
"				(*CUDA_LCC).da[(*CUDA_LCC).icol] = tmpSwap;\n"
"\n"
"				//SWAP(b[irow],b[icol])\n"
"			}\n"
"\n"
"			(*CUDA_LCC).indxr[i] = irow;\n"
"			(*CUDA_LCC).indxc[i] = (*CUDA_LCC).icol;\n"
"\n"
"			//if (blockIdx.x == 0)\n"
"			//	printf(\"i: %3d, irow: %3d, icol: %3d\\n\", i, irow, (*CUDA_LCC).icol);\n"
"\n"
"			int covarIdx = (*CUDA_LCC).icol * (*CUDA_CC).Mfit1 + (*CUDA_LCC).icol;\n"
"\n"
"			if ((*CUDA_LCC).covar[covarIdx] == 0.0)\n"
"			{\n"
"				j = 0;\n"
"				for (int l = 1; l <= (*CUDA_CC).ma; l++)\n"
"				{\n"
"					if ((*CUDA_CC).ia[l])\n"
"					{\n"
"						j++;\n"
"						(*CUDA_LCC).atry[l] = (*CUDA_LCC).cg[l] + (*CUDA_LCC).da[j];\n"
"					}\n"
"				}\n"
"\n"
"				return(2);\n"
"			}\n"
"\n"
"			//<<<<<<<<<<  (*CUDA_LCC).\n"
"			(*CUDA_LCC).pivinv = 1.0 / (*CUDA_LCC).covar[covarIdx];\n"
"			(*CUDA_LCC).covar[covarIdx] = 1.0;\n"
"\n"
"\n"
"			(*CUDA_LCC).da[(*CUDA_LCC).icol] = (*CUDA_LCC).da[(*CUDA_LCC).icol] * (*CUDA_LCC).pivinv;\n"
"			//b[icol] *= pivinv;\n"
"\n"
"			//if(blockIdx.x == 0)\n"
"			//	printf(\"[%d] i[%2d] da[%4d]: %10.7f\\n\", blockIdx.x, i, (*CUDA_LCC).icol, (*CUDA_LCC).da[(*CUDA_LCC).icol]); // da - OK\n"
"\n"
"			//if (blockIdx.x == 0)\n"
"			//	printf(\"[%d] i[%2d] pivinv: %10.7f\\n\", blockIdx.x, i, (*CUDA_LCC).pivinv); // pivinv - OK\n"
"\n"
"		}\n"
"\n"
"		barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"\n"
"\n"
"		//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"		//	printf(\"[%d] icol: %5d, mfit1: %3d, l: %3d\\n\", blockIdx.x, icol, (*CUDA_CC).Mfit1, l);\n"
"\n"
"		for (l = brtmpl; l <= brtmph; l++)\n"
"		{\n"
"			int qq = (*CUDA_LCC).icol * (*CUDA_CC).Mfit1 + l;\n"
"			double covar1 = (*CUDA_LCC).covar[qq] * (*CUDA_LCC).pivinv;\n"
"			//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"			//	printf(\"[%d][%3d] i[%3d] l[%3d] icol: %3d, pivinv: %10.7f, covar[%4d]: %10.7f, covar: %10.7f\\n\",\n"
"			//		blockIdx.x, threadIdx.x, i, l, (*CUDA_LCC).icol, (*CUDA_LCC).pivinv, qq, (*CUDA_LCC).covar[qq], covar1);\n"
"\n"
"			//barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);// | CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n"
"\n"
"			//covar[qq] = 1.0;\n"
"			//(*CUDA_LCC).covar[qq] = (*CUDA_LCC).covar[qq] * pivinv;\n"
"			(*CUDA_LCC).covar[qq] = covar1;\n"
"		}\n"
"\n"
"		barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"\n"
"		for (ll = brtmpl; ll <= brtmph; ll++)\n"
"		{\n"
"			//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"			//	printf(\"i[%d%3d] ll: %4d, brtmpl: %3d, brtmph; %3d\\n\", i, ll, brtmpl, brtmph);\n"
"\n"
"			if (ll != (*CUDA_LCC).icol)\n"
"			{\n"
"				int ixx = ll * (*CUDA_CC).Mfit1;\n"
"				int jxx = (*CUDA_LCC).icol * (*CUDA_CC).Mfit1;\n"
"				dum = (*CUDA_LCC).covar[ixx + (*CUDA_LCC).icol];\n"
"				(*CUDA_LCC).covar[ixx + (*CUDA_LCC).icol] = 0.0;\n"
"				ixx++;\n"
"				jxx++;\n"
"				for (l = 1; l <= n; l++, ixx++, jxx++)\n"
"				{\n"
"					(*CUDA_LCC).covar[ixx] -= (*CUDA_LCC).covar[jxx] * dum;\n"
"				}\n"
"\n"
"				(*CUDA_LCC).da[ll] -= (*CUDA_LCC).da[(*CUDA_LCC).icol] * dum;\n"
"				//b[ll] -= b[icol]*dum;\n"
"\n"
"			}\n"
"		}\n"
"\n"
"		barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"	}\n"
"\n"
"	if (threadIdx.x == 0)\n"
"	{\n"
"		for (l = n; l >= 1; l--)\n"
"		{\n"
"			if ((*CUDA_LCC).indxr[l] != (*CUDA_LCC).indxc[l])\n"
"			{\n"
"				for (k = 1; k <= n; k++)\n"
"				{\n"
"					//SwapDouble((*CUDA_LCC).covar[k * (*CUDA_CC).Mfit1 + (*CUDA_LCC).indxr[l]], (*CUDA_LCC).covar[k * (*CUDA_CC).Mfit1 + (*CUDA_LCC).indxc[l]]);\n"
"					tmpSwap = (*CUDA_LCC).covar[k * (*CUDA_CC).Mfit1 + (*CUDA_LCC).indxr[l]];\n"
"					(*CUDA_LCC).covar[k * (*CUDA_CC).Mfit1 + (*CUDA_LCC).indxr[l]] = (*CUDA_LCC).covar[k * (*CUDA_CC).Mfit1 + (*CUDA_LCC).indxc[l]];\n"
"					(*CUDA_LCC).covar[k * (*CUDA_CC).Mfit1 + (*CUDA_LCC).indxc[l]] = tmpSwap;\n"
"				}\n"
"			}\n"
"		}\n"
"	}\n"
"\n"
"	barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"\n"
"	return(0);\n"
"}\n"
"// #undef SWAP\n"
" //from Numerical Recipes\n"
"\n"
"//N.B. The foll. L-M routines are modified versions of Press et al.\n"
"//  converted from Mikko\'s fortran code\n"
"\n"
"//  8.11.2006\n"
"\n"
"\n"
"int mrqmin_1_end(\n"
"	__global struct mfreq_context* CUDA_LCC,\n"
"	__global struct freq_context* CUDA_CC)\n"
"	//int mrqmin_1_end(struct mfreq_context* CUDA_LCC, struct freq_context* CUDA_CC, int* sh_icol, int* sh_irow, double* sh_big, int icol, double pivinv)\n"
"{\n"
"	//const int* ia = (*CUDA_CC).ia;\n"
"	//const int ma = (*CUDA_CC).ma;\n"
"	//const int mfit = (*CUDA_CC).Mfit;\n"
"	//const int mfit1 = (*CUDA_CC).Mfit1;\n"
"\n"
"	int j;\n"
"	int3 threadIdx, blockIdx;\n"
"	threadIdx.x = get_local_id(0);\n"
"	blockIdx.x = get_group_id(0);\n"
"\n"
"	int ma = (*CUDA_CC).ma;\n"
"\n"
"	//precalc thread boundaries\n"
"	int tmph, tmpl;\n"
"	tmph = ma / BLOCK_DIM;\n"
"	if (ma % BLOCK_DIM) tmph++;\n"
"	tmpl = threadIdx.x * tmph;\n"
"	tmph = tmpl + tmph;\n"
"	if (tmph > ma) tmph = ma;\n"
"	tmpl++;\n"
"	//\n"
"	int brtmph, brtmpl;\n"
"	brtmph = (*CUDA_CC).Mfit / BLOCK_DIM;\n"
"	if ((*CUDA_CC).Mfit % BLOCK_DIM) brtmph++;\n"
"	brtmpl = threadIdx.x * brtmph;\n"
"	brtmph = brtmpl + brtmph;\n"
"	if (brtmph > (*CUDA_CC).Mfit) brtmph = (*CUDA_CC).Mfit;\n"
"	brtmpl++;\n"
"\n"
"	if ((*CUDA_LCC).isAlamda)\n"
"	{\n"
"		for (j = tmpl; j <= tmph; j++)\n"
"		{\n"
"			(*CUDA_LCC).atry[j] = (*CUDA_LCC).cg[j];\n"
"		}\n"
"\n"
"	}\n"
"\n"
"	barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"\n"
"	for (j = brtmpl; j <= brtmph; j++)\n"
"	{\n"
"		int ixx = j * (*CUDA_CC).Mfit1 + 1;\n"
"		for (int k = 1; k <= (*CUDA_CC).Mfit; k++, ixx++)\n"
"		{\n"
"			(*CUDA_LCC).covar[ixx] = (*CUDA_LCC).alpha[ixx];\n"
"\n"
"			//if(blockIdx.x == 0 && threadIdx.x == 0 && ixx == 56)\n"
"			//	printf(\"[%d][%3d] alpha[%3d]: %10.7f\\n\", blockIdx.x, threadIdx.x, ixx, (*CUDA_LCC).alpha[ixx]); // On second pass alpha[56] = 0.0000 instead of 80.8776359 ?!?\n"
"				//printf(\"[%d][%3d] covar[%3d]: %10.7f\\n\", blockIdx.x, threadIdx.x, ixx, (*CUDA_LCC).covar[ixx]);\n"
"		}\n"
"\n"
"		int qq = j * (*CUDA_CC).Mfit1 + j;\n"
"		(*CUDA_LCC).covar[qq] = (*CUDA_LCC).alpha[qq] * (1 + (*CUDA_LCC).Alamda);\n"
"\n"
"		//if (blockIdx.x == 0)\n"
"		//	printf(\"[%3d] j[%3d] alpha[%3d]: %10.7f, 1 + Alamda: %10.7f, covar[%3d]: %10.7f\\n\",\n"
"		//		threadIdx.x, j, qq, (*CUDA_LCC).alpha[qq], 1 + (*CUDA_LCC).Alamda, qq, (*CUDA_LCC).covar[qq]);\n"
"\n"
"		(*CUDA_LCC).da[j] = (*CUDA_LCC).beta[j];\n"
"\n"
"		//if (blockIdx.x == 0)\n"
"		//	printf(\"[%d][%3d] da[%3d]: %10.7f\\n\", blockIdx.x, threadIdx.x, j, (*CUDA_LCC).da[j]); // da -> OK\n"
"\n"
"		//if(threadIdx.x == 1)\n"
"		//	printf(\"[%d] covar[%3d]: %10.7f, alpha[%3d]: %10.7f, (1 + Alamda: %10.7f)\\n\",\n"
"		//		blockIdx.x, qq, (*CUDA_LCC).covar[qq], qq, (*CUDA_LCC).alpha[qq], 1 + (*CUDA_LCC).Alamda);\n"
"	}\n"
"\n"
"	//if(threadIdx.x == 0)\n"
"	//	printf(\"[%d] covar[56]: %10.7f\\n\", blockIdx.x,  (*CUDA_LCC).covar[56]);\n"
"	//sh_icol[threadIdx.x] = threadIdx.x;\n"
"\n"
"	barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"\n"
"	// ---- GAUS ERROR CODE ----\n"
"	int err_code = gauss_errc(CUDA_LCC, CUDA_CC);\n"
"\n"
"	//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"	//	printf(\"mrqmin_1_end >>> [%3d] ma[%d3] err_code: %3d\\n\", threadIdx.x, ma, err_code);\n"
"\n"
"	if (err_code)\n"
"	{\n"
"		return err_code;\n"
"	}\n"
"\n"
"	//err_code = gauss_errc(CUDA_LCC, CUDA_mfit, (*CUDA_LCC).da);\n"
"\n"
"	//     __syncthreads(); inside gauss\n"
"\n"
"	if (threadIdx.x == 0)\n"
"	{\n"
"\n"
"		//		if (err_code != 0) return(err_code);  \"bacha na sync threads\" - Watch out for Sync Threads\n"
"\n"
"		j = 0;\n"
"		for (int l = 1; l <= ma; l++)\n"
"			if ((*CUDA_CC).ia[l])\n"
"			{\n"
"				j++;\n"
"				(*CUDA_LCC).atry[l] = (*CUDA_LCC).cg[l] + (*CUDA_LCC).da[j];\n"
"\n"
"				//if (blockIdx.x == 0 && j == 50)\n"
"				//	printf(\"[mrqmin_1_end] [%3d] atry[%3d]: %10.7f, cg[%3d]: %10.7f, da[%3d]: %10.7f\\n\",\n"
"				//		threadIdx.x, j, (*CUDA_LCC).atry[j], j, (*CUDA_LCC).cg[l], j, (*CUDA_LCC).da[j]);\n"
"			}\n"
"	}\n"
"\n"
"	barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"\n"
"	return err_code;\n"
"}\n"
"\n"
"void mrqmin_2_end(\n"
"	__global struct mfreq_context* CUDA_LCC,\n"
"	__global struct freq_context* CUDA_CC) //, int* ia, int ma)\n"
"{\n"
"	int j, k, l;\n"
"	int3 blockIdx, threadIdx;\n"
"	blockIdx.x = get_group_id(0);\n"
"	threadIdx.x = get_local_id(0);\n"
"\n"
"	if ((*CUDA_LCC).Chisq < (*CUDA_LCC).Ochisq)\n"
"	{\n"
"		(*CUDA_LCC).Alamda = (*CUDA_LCC).Alamda / (*CUDA_CC).Alamda_incr;\n"
"		for (j = 1; j <= (*CUDA_CC).Mfit; j++)\n"
"		{\n"
"			for (k = 1; k <= (*CUDA_CC).Mfit; k++)\n"
"			{\n"
"				(*CUDA_LCC).alpha[j * (*CUDA_CC).Mfit1 + k] = (*CUDA_LCC).covar[j * (*CUDA_CC).Mfit1 + k];\n"
"\n"
"				//if (blockIdx.x == 0)\n"
"				//	printf(\"alpha[%3d]: %10.7f\\n\", (*CUDA_LCC).alpha[j * (*CUDA_CC).Mfit1 + k]);\n"
"			}\n"
"\n"
"			(*CUDA_LCC).beta[j] = (*CUDA_LCC).da[j];\n"
"		}\n"
"		for (l = 1; l <= (*CUDA_CC).ma; l++)\n"
"		{\n"
"			(*CUDA_LCC).cg[l] = (*CUDA_LCC).atry[l];\n"
"		}\n"
"	}\n"
"	else\n"
"	{\n"
"		(*CUDA_LCC).Alamda = (*CUDA_CC).Alamda_incr * (*CUDA_LCC).Alamda;\n"
"		(*CUDA_LCC).Chisq = (*CUDA_LCC).Ochisq;\n"
"	}\n"
"\n"
"\n"
"}\n"
"kernel void k(){}\n"
"kernel void ClCheckEnd(\n"
"	__global int* CUDA_End,\n"
"	int theEnd)\n"
"{\n"
"	int3 blockIdx;\n"
"	blockIdx.x = get_group_id(0);\n"
"\n"
"	if (blockIdx.x == 0)\n"
"		*CUDA_End = theEnd;\n"
"\n"
"	//if (blockIdx.x == 0)\n"
"		//printf(\"CheckEnd CUDA_End: %2d\\n\", *CUDA_End);\n"
"\n"
"}\n"
"\n"
"__kernel void ClCalculatePrepare(\n"
"	__global struct mfreq_context* CUDA_mCC,\n"
"	__global struct freq_result* CUDA_FR,\n"
"	__global int* CUDA_End,\n"
"	double freq_start,\n"
"	double freq_step,\n"
"	int n_max,\n"
"	int n_start)\n"
"{\n"
"	int3 blockIdx;\n"
"	blockIdx.x = get_group_id(0);\n"
"	int x = blockIdx.x;\n"
"\n"
"	__global struct mfreq_context* CUDA_LCC = &CUDA_mCC[blockIdx.x];\n"
"	__global struct freq_result* CUDA_LFR = &CUDA_FR[blockIdx.x];\n"
"\n"
"	int n = n_start + blockIdx.x;\n"
"\n"
"\n"
"	//zero context\n"
"	if (n > n_max)\n"
"	{\n"
"		//CUDA_mCC[x].isInvalid = 1;\n"
"		(*CUDA_LCC).isInvalid = 1;\n"
"		(*CUDA_FR).isInvalid = 1;\n"
"		return;\n"
"	}\n"
"	else\n"
"	{\n"
"		//CUDA_mCC[x].isInvalid = 0;\n"
"		(*CUDA_LCC).isInvalid = 0;\n"
"		(*CUDA_FR).isInvalid = 0;\n"
"	}\n"
"\n"
"	//printf(\"[%d] n_start: %d | n_max: %d | n: %d \\n\", blockIdx.x, n_start, n_max, n);\n"
"\n"
"	//printf(\"Idx: %d | isInvalid: %d\\n\", x, CUDA_CC[x].isInvalid);\n"
"	//printf(\"Idx: %d | isInvalid: %d\\n\", x, (*CUDA_LCC).isInvalid);\n"
"\n"
"	//CUDA_mCC[x].freq = freq_start - (n - 1) * freq_step;\n"
"	(*CUDA_LCC).freq = freq_start - (n - 1) * freq_step;\n"
"\n"
"	///* initial poles */\n"
"	(*CUDA_LFR).per_best = 0.0;\n"
"	(*CUDA_LFR).dark_best = 0.0;\n"
"	(*CUDA_LFR).la_best = 0.0;\n"
"	(*CUDA_LFR).be_best = 0.0;\n"
"	(*CUDA_LFR).dev_best = 1e40;\n"
"\n"
"	//printf(\"n: %4d, CUDA_CC[%3d].freq: %10.7f, CUDA_FR[%3d].la_best: %10.7f, isInvalid: %4d \\n\", n, x, (*CUDA_LCC).freq, x, (*CUDA_LFR).la_best, (*CUDA_LCC).isInvalid);\n"
"\n"
"	//barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); // TEST\n"
"	//if (blockIdx.x == 0)\n"
"		//printf(\"Prepare CUDA_End: %2d\\n\", *CUDA_End);\n"
"}\n"
"\n"
"__kernel void ClCalculatePreparePole(\n"
"	__global struct mfreq_context* CUDA_mCC,\n"
"	__global struct freq_context* CUDA_CC,\n"
"	__global struct freq_result* CUDA_FR,\n"
"	__global double* CUDA_cg_first,\n"
"	__global int* CUDA_End,\n"
"    __global double freq_context* CUDA_CC2,\n"
"	//double CUDA_cl,\n"
"	int m)\n"
"{\n"
"	int3 blockIdx, threadIdx;\n"
"	blockIdx.x = get_group_id(0);\n"
"	threadIdx.x = get_local_id(0);\n"
"	int x = blockIdx.x;\n"
"\n"
"	//const auto CUDA_LCC = &CUDA_CC[blockIdx.x];\n"
"	//const auto CUDA_LFR = &CUDA_FR[blockIdx.x];\n"
"\n"
"	__global struct mfreq_context* CUDA_LCC = &CUDA_mCC[blockIdx.x];\n"
"	__global struct freq_result* CUDA_LFR = &CUDA_FR[blockIdx.x];\n"
"\n"
"	//int t = *CUDA_End;\n"
"	//*CUDA_End = 13;\n"
"	//printf(\"[%d] PreparePole t: %d, CUDA_End: %d\\n\", x, t, *CUDA_End);\n"
"\n"
"\n"
"	if ((*CUDA_LCC).isInvalid)\n"
"	{\n"
"		//atomic_add(CUDA_End, 1);\n"
"		atomic_inc(CUDA_End);\n"
"		//printf(\"prepare pole %d \", (*CUDA_End));\n"
"\n"
"		(*CUDA_FR).isReported = 0; //signal not to read result\n"
"\n"
"		//printf(\"[%d] isReported: %d \\n\", blockIdx.x, (*CUDA_FR).isReported);\n"
"\n"
"		return;\n"
"	}\n"
"\n"
"	//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"	//	printf(\"[Device] PreparePole > ma: %d\\n\", (*CUDA_CC).ma);\n"
"\n"
"	double period = 1.0 / (*CUDA_LCC).freq;\n"
"\n"
"	//* starts from the initial ellipsoid */\n"
"	for (int i = 1; i <= (*CUDA_CC).Ncoef; i++)\n"
"	{\n"
"		(*CUDA_LCC).cg[i] = CUDA_cg_first[i];\n"
"		//if(blockIdx.x == 0)\n"
"		//	printf(\"cg[%3d]: %10.7f\\n\", i, CUDA_cg_first[i]);\n"
"	}\n"
"	//printf(\"Idx: %d | m: %d | Ncoef: %d\\n\", x, m, (*CUDA_CC).Ncoef);\n"
"	//printf(\"cg[%d]: %.7f\\n\", x, CUDA_CC[x].cg[CUDA_CC[x].Ncoef + 1]);\n"
"	//printf(\"Idx: %d | beta_pole[%d]: %.7f\\n\", x, m, CUDA_CC[x].beta_pole[m]);\n"
"\n"
"	(*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 1] = (*CUDA_CC).beta_pole[m];\n"
"	(*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 2] = (*CUDA_CC).lambda_pole[m];\n"
"	//if (blockIdx.x == 0)\n"
"	//{\n"
"	//	printf(\"cg[%3d]: %10.7f\\n\", (*CUDA_CC).Ncoef + 1, (*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 1]);\n"
"	//	printf(\"cg[%3d]: %10.7f\\n\", (*CUDA_CC).Ncoef + 2, (*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 2]);\n"
"	//}\n"
"	//printf(\"cg[%d]: %.7f | cg[%d]: %.7f\\n\", (*CUDA_CC).Ncoef + 1, (*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 1], (*CUDA_CC).Ncoef + 2, (*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 2]);\n"
"\n"
"	/* The formulas use beta measured from the pole */\n"
"	(*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 1] = 90.0 - (*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 1];\n"
"	//printf(\"90 - cg[%d]: %.7f\\n\", (*CUDA_CC).Ncoef + 1, (*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 1]);\n"
"\n"
"	/* conversion of lambda, beta to radians */\n"
"	(*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 1] = DEG2RAD * (*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 1];\n"
"	(*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 2] = DEG2RAD * (*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 2];\n"
"	//printf(\"cg[%d]: %.7f | cg[%d]: %.7f\\n\", (*CUDA_CC).Ncoef + 1, (*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 1], (*CUDA_CC).Ncoef + 2, (*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 2]);\n"
"\n"
"	/* Use omega instead of period */\n"
"	(*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 3] = 24.0 * 2.0 * PI / period;\n"
"\n"
"	//if (threadIdx.x == 0)\n"
"	//{\n"
"	//	printf(\"[%3d] cg[%3d]: %10.7f, period: %10.7f\\n\", blockIdx.x, (*CUDA_CC).Ncoef + 3, (*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 3], period);\n"
"	//}\n"
"\n"
"	for (int i = 1; i <= (*CUDA_CC).Nphpar; i++)\n"
"	{\n"
"		(*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 3 + i] = (*CUDA_CC).par[i];\n"
"		//              ia[Ncoef+3+i] = ia_par[i]; moved to global\n"
"		//if (blockIdx.x == 0)\n"
"		//	printf(\"cg[%3d]: %10.7f\\n\", (*CUDA_CC).Ncoef + 3 + i, (*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 3 + i]);\n"
"\n"
"	}\n"
"\n"
"	/* Lommel-Seeliger part */\n"
"	(*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 3 + (*CUDA_CC).Nphpar + 2] = 1;\n"
"	//if (blockIdx.x == 0)\n"
"	//{\n"
"	//	printf(\"cg[%3d]: %10.7f\\n\", (*CUDA_CC).Ncoef + 3 + (*CUDA_CC).Nphpar + 2, (*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 3 + (*CUDA_CC).Nphpar + 2]);\n"
"	//}\n"
"\n"
"	/* Use logarithmic formulation for Lambert to keep it positive */\n"
"	(*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 3 + (*CUDA_CC).Nphpar + 1] = log((*CUDA_CC).cl);\n"
"	//(*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 3 + (*CUDA_CC).Nphpar + 1] = (*CUDA_CC).logCl;   //log((*CUDA_CC).cl);\n"
"\n"
"\n"
"	//if (blockIdx.x == 0)\n"
"	//{\n"
"	//	printf(\"cg[%3d]: %10.7f\\n\", (*CUDA_CC).Ncoef + 3 + (*CUDA_CC).Nphpar + 1, (*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 3 + (*CUDA_CC).Nphpar + 1]);\n"
"	//}\n"
"	//printf(\"cg[%d]: %.7f\\n\", (*CUDA_CC).Ncoef + 3 + (*CUDA_CC).Nphpar + 1, (*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 3 + (*CUDA_CC).Nphpar + 1]);\n"
"\n"
"	/* Levenberg-Marquardt loop */\n"
"	// moved to global iter_max,iter_min,iter_dif_max\n"
"	//\n"
"	(*CUDA_LCC).rchisq = -1;\n"
"	(*CUDA_LCC).Alamda = -1;\n"
"	(*CUDA_LCC).Niter = 0;\n"
"	(*CUDA_LCC).iter_diff = 1e40;\n"
"	(*CUDA_LCC).dev_old = 1e30;\n"
"	(*CUDA_LCC).dev_new = 0;\n"
"	//	(*CUDA_LCC).Lastcall=0; always ==0\n"
"	(*CUDA_LFR).isReported = 0;\n"
"\n"
"    for(int i = 0; i < MAX_N_OBS + 1; i++)\n"
"    {\n"
"        (*CUDA_CC2).Brightness[i] = (*CUDA_CC).Brightness[i];\n"
"    }\n"
"}\n"
"\n"
"__kernel void ClCalculateIter1Begin(\n"
"	__global struct mfreq_context* CUDA_mCC,\n"
"	__global struct freq_result* CUDA_FR,\n"
"	__global int* CUDA_End,\n"
"	int CUDA_n_iter_min,\n"
"	int CUDA_n_iter_max,\n"
"	double CUDA_iter_diff_max,\n"
"	double CUDA_Alamda_start)\n"
"{\n"
"	int3 blockIdx, threadIdx;\n"
"	blockIdx.x = get_group_id(0);\n"
"	threadIdx.x = get_local_id(0);\n"
"	int x = blockIdx.x;\n"
"\n"
"	//const auto CUDA_LCC = &CUDA_CC[blockIdx.x];\n"
"	//const auto CUDA_LFR = &CUDA_FR[blockIdx.x];\n"
"\n"
"	__global struct mfreq_context* CUDA_LCC = &CUDA_mCC[blockIdx.x];\n"
"	__global struct freq_result* CUDA_LFR = &CUDA_FR[blockIdx.x];\n"
"\n"
"	if ((*CUDA_LCC).isInvalid)\n"
"	{\n"
"		return;\n"
"	}\n"
"\n"
"	//                                   ?    < 50                                 ?       > 0                                   ?      < 0\n"
"	(*CUDA_LCC).isNiter = (((*CUDA_LCC).Niter < CUDA_n_iter_max) && ((*CUDA_LCC).iter_diff > CUDA_iter_diff_max)) || ((*CUDA_LCC).Niter < CUDA_n_iter_min);\n"
"	(*CUDA_FR).isNiter = (*CUDA_LCC).isNiter;\n"
"\n"
"	//printf(\"[%d] isNiter: %d, Alamda: %10.7f\\n\", blockIdx.x, (*CUDA_LCC).isNiter, (*CUDA_LCC).Alamda);\n"
"\n"
"	if ((*CUDA_LCC).isNiter)\n"
"	{\n"
"		if ((*CUDA_LCC).Alamda < 0)\n"
"		{\n"
"			(*CUDA_LCC).isAlamda = 1;\n"
"			(*CUDA_LCC).Alamda = CUDA_Alamda_start; /* initial alambda */\n"
"		}\n"
"		else\n"
"		{\n"
"			(*CUDA_LCC).isAlamda = 0;\n"
"		}\n"
"	}\n"
"	else\n"
"	{\n"
"		if (!(*CUDA_LFR).isReported)\n"
"		{\n"
"			//int oldEnd = *CUDA_End;\n"
"			//atomic_add(CUDA_End, 1);\n"
"			int t = *CUDA_End;\n"
"			atomic_inc(CUDA_End);\n"
"\n"
"			//printf(\"[%d] t: %2d, Begin %2d\\n\", blockIdx.x, t, *CUDA_End);\n"
"\n"
"			(*CUDA_LFR).isReported = 1;\n"
"		}\n"
"	}\n"
"\n"
"	//if (threadIdx.x == 1)\n"
"	//	printf(\"[begin] Alamda: %10.7f\\n\", (*CUDA_LCC).Alamda);\n"
"	//barrier(CLK_GLOBAL_MEM_FENCE); // TEST\n"
"}\n"
"\n"
"__kernel void ClCalculateIter1Mrqcof1Start(\n"
"	__global struct mfreq_context* CUDA_mCC,\n"
"	__global struct freq_context* CUDA_CC)\n"
"	//__global int* CUDA_End)\n"
"{\n"
"	int3 blockIdx, threadIdx;\n"
"	blockIdx.x = get_group_id(0);\n"
"	threadIdx.x = get_local_id(0);\n"
"	int x = blockIdx.x;\n"
"\n"
"	//const auto CUDA_LCC = &CUDA_CC[blockIdx.x];\n"
"	__global struct mfreq_context* CUDA_LCC = &CUDA_mCC[blockIdx.x];\n"
"	//double* dytemp = &CUDA_Dytemp[blockIdx.x];\n"
"\n"
"	//double* Area = &CUDA_mCC[0].Area;\n"
"\n"
"	//if (blockIdx.x == 0)\n"
"	//	printf(\"[%d][%3d] [Mrqcof1Start]\\n\", blockIdx.x, threadIdx.x);\n"
"		//printf(\"isInvalid: %3d, isNiter: %3d, isAlamda: %3d\\n\", (*CUDA_LCC).isInvalid, (*CUDA_LCC).isNiter, (*CUDA_LCC).isAlamda);\n"
"\n"
"	if ((*CUDA_LCC).isInvalid) return;\n"
"\n"
"	if (!(*CUDA_LCC).isNiter) return;\n"
"\n"
"	if (!(*CUDA_LCC).isAlamda) return; //>> 0\n"
"\n"
"	// => mrqcof_start(CUDA_LCC, (*CUDA_LCC).cg, (*CUDA_LCC).alpha, (*CUDA_LCC).beta);\n"
"	mrqcof_start(CUDA_LCC, CUDA_CC, (*CUDA_LCC).cg, (*CUDA_LCC).alpha, (*CUDA_LCC).beta);\n"
"}\n"
"\n"
"__kernel void ClCalculateIter1Mrqcof1Matrix(\n"
"	__global struct mfreq_context* CUDA_mCC,\n"
"	__global struct freq_context* CUDA_CC,\n"
"	const int lpoints)\n"
"{\n"
"	int3 blockIdx;\n"
"	blockIdx.x = get_group_id(0);\n"
"	int x = blockIdx.x;\n"
"\n"
"	//const auto CUDA_LCC = &CUDA_CC[blockIdx.x];\n"
"	__global struct mfreq_context* CUDA_LCC = &CUDA_mCC[blockIdx.x];\n"
"\n"
"	if ((*CUDA_LCC).isInvalid) return;\n"
"\n"
"	if (!(*CUDA_LCC).isNiter) return;\n"
"\n"
"	if (!(*CUDA_LCC).isAlamda) return;\n"
"\n"
"	__local int num; // __shared__\n"
"\n"
"	int3 localIdx;\n"
"	localIdx.x = get_local_id(0);\n"
"	if (localIdx.x == 0)\n"
"	{\n"
"		num = 0;\n"
"	}\n"
"\n"
"	mrqcof_matrix(CUDA_LCC, CUDA_CC, (*CUDA_LCC).cg, lpoints, num);\n"
"}\n"
"\n"
"__kernel void ClCalculateIter1Mrqcof1Curve1(\n"
"	__global struct mfreq_context* CUDA_mCC,\n"
"	__global struct freq_context* CUDA_CC,\n"
"	const int inrel,\n"
"	const int lpoints)\n"
"{\n"
"	int3 blockIdx, threadIdx;\n"
"	blockIdx.x = get_group_id(0);\n"
"	threadIdx.x = get_local_id(0);\n"
"	int x = blockIdx.x;\n"
"\n"
"	//const auto CUDA_LCC = &CUDA_CC[blockIdx.x];\n"
"	__global struct mfreq_context* CUDA_LCC = &CUDA_mCC[blockIdx.x];\n"
"	//double* dytemp = &CUDA_Dytemp[blockIdx.x];\n"
"\n"
"	if ((*CUDA_LCC).isInvalid) return;\n"
"\n"
"	if (!(*CUDA_LCC).isNiter) return;\n"
"\n"
"	if (!(*CUDA_LCC).isAlamda) return;\n"
"\n"
"	__local int num;  // __shared__\n"
"	__local double tmave[BLOCK_DIM];\n"
"\n"
"	if (threadIdx.x == 0)\n"
"	{\n"
"		num = 0;\n"
"	}\n"
"\n"
"	mrqcof_curve1(CUDA_LCC, CUDA_CC, (*CUDA_LCC).cg, tmave, inrel, lpoints, num);\n"
"\n"
"	//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"	//	printf(\"[Mrqcof1Curve1] [%d][%3d] alpha[56]: %10.7f\\n\", blockIdx.x, threadIdx.x, (*CUDA_LCC).alpha[56]);\n"
"\n"
"	//if (blockIdx.x == 0)\n"
"	//	printf(\"dytemp[8636]: %10.7f\\n\", dytemp[8636]);\n"
"}\n"
"\n"
"__kernel void ClCalculateIter1Mrqcof1Curve1Last(\n"
"	__global struct mfreq_context* CUDA_mCC,\n"
"	__global struct freq_context* CUDA_CC,\n"
"	const int inrel,\n"
"	const int lpoints)\n"
"{\n"
"	int3 blockIdx, threadIdx;\n"
"	blockIdx.x = get_group_id(0);\n"
"	threadIdx.x = get_local_id(0);\n"
"\n"
"	//const auto CUDA_LCC = &CUDA_CC[blockIdx.x];\n"
"	__global struct mfreq_context* CUDA_LCC = &CUDA_mCC[blockIdx.x];\n"
"	//double* dytemp = &CUDA_Dytemp[blockIdx.x];\n"
"\n"
"	if ((*CUDA_LCC).isInvalid) return;\n"
"\n"
"	if (!(*CUDA_LCC).isNiter) return;\n"
"\n"
"	if (!(*CUDA_LCC).isAlamda) return;\n"
"\n"
"	__local double res[BLOCK_DIM];\n"
"\n"
"	//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"	//	printf(\"Mrqcof1Curve1Last\\n\");\n"
"\n"
"	mrqcof_curve1_last(CUDA_LCC, CUDA_CC, (*CUDA_LCC).cg, (*CUDA_LCC).alpha, (*CUDA_LCC).beta, res, inrel, lpoints);\n"
"	//if (threadIdx.x == 0)\n"
"	//{\n"
"	//	int i = 56;\n"
"	//	//for (int i = 1; i <= 60; i++) {\n"
"	//		printf(\"[%d] alpha[%2d]: %10.7f\\n\", blockIdx.x, i, (*CUDA_LCC).alpha[i]);\n"
"	//	//}\n"
"	//}\n"
"}\n"
"\n"
"__kernel void ClCalculateIter1Mrqcof1Curve2(\n"
"	__global struct mfreq_context* CUDA_mCC,\n"
"	__global struct freq_context* CUDA_CC,\n"
"	const int inrel,\n"
"	const int lpoints)\n"
"{\n"
"	int3 blockIdx, threadIdx;\n"
"	blockIdx.x = get_group_id(0);\n"
"	threadIdx.x = get_local_id(0);\n"
"\n"
"	//const auto CUDA_LCC = &CUDA_CC[blockIdx.x];\n"
"	__global struct mfreq_context* CUDA_LCC = &CUDA_mCC[blockIdx.x];\n"
"\n"
"	//if (blockIdx.x == 0)\n"
"	//printf(\"[%3d] isInvalid: %3d, isNiter: %3d, isAlamda: %3d\\n\", threadIdx.x, (*CUDA_LCC).isInvalid, (*CUDA_LCC).isNiter, (*CUDA_LCC).isAlamda);\n"
"\n"
"	if ((*CUDA_LCC).isInvalid) return;\n"
"\n"
"	if (!(*CUDA_LCC).isNiter) return;\n"
"\n"
"	if (!(*CUDA_LCC).isAlamda) return;\n"
"\n"
"	mrqcof_curve2(CUDA_LCC, CUDA_CC, (*CUDA_LCC).alpha, (*CUDA_LCC).beta, inrel, lpoints);\n"
"\n"
"	//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"	//	printf(\"[Mrqcof1Curve2] [%d][%3d] alpha[56]: %10.7f\\n\", blockIdx.x, threadIdx.x, (*CUDA_LCC).alpha[56]);\n"
"\n"
"	//if (threadIdx.x == 0)\n"
"	//{\n"
"	//	int i = 56;\n"
"	//	//for (int i = 1; i <= 60; i++) {\n"
"	//	printf(\"[%d] alpha[%2d]: %10.7f\\n\", blockIdx.x, i, (*CUDA_LCC).alpha[i]);\n"
"	//	//}\n"
"	//}\n"
"}\n"
"\n"
"__kernel void ClCalculateIter1Mrqcof1End(\n"
"	__global struct mfreq_context* CUDA_mCC,\n"
"	__global struct freq_context* CUDA_CC)\n"
"{\n"
"	int3 blockIdx, threadIdx;\n"
"	blockIdx.x = get_group_id(0);\n"
"	threadIdx.x = get_local_id(0);\n"
"\n"
"	//const auto CUDA_LCC = &CUDA_CC[blockIdx.x];\n"
"	__global struct mfreq_context* CUDA_LCC = &CUDA_mCC[blockIdx.x];\n"
"\n"
"	if ((*CUDA_LCC).isInvalid) return;\n"
"\n"
"	if (!(*CUDA_LCC).isNiter) return;\n"
"\n"
"	if (!(*CUDA_LCC).isAlamda) return;\n"
"\n"
"	//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"	//	printf(\"Mrqcof1End\\n\");\n"
"\n"
"\n"
"	(*CUDA_LCC).Ochisq = mrqcof_end(CUDA_LCC, CUDA_CC, (*CUDA_LCC).alpha);\n"
"\n"
"\n"
"	////if (threadIdx.x == 0)\n"
"	////{\n"
"	//	int i = 56;\n"
"	//	//for (int i = 1; i <= 60; i++) {\n"
"	//	printf(\"[%d] alpha[%2d]: %10.7f\\n\", blockIdx.x, i, (*CUDA_LCC).alpha[i]);\n"
"	//	//}\n"
"	////}\n"
"}\n"
"\n"
"__kernel void ClCalculateIter1Mrqmin1End(\n"
"	__global struct mfreq_context* CUDA_mCC,\n"
"	__global struct freq_context* CUDA_CC)\n"
"{\n"
"	int3 blockIdx, threadIdx;\n"
"	blockIdx.x = get_group_id(0);\n"
"	threadIdx.x = get_local_id(0);\n"
"\n"
"	//const auto CUDA_LCC = &CUDA_CC[blockIdx.x];\n"
"	__global struct mfreq_context* CUDA_LCC = &CUDA_mCC[blockIdx.x];\n"
"\n"
"	if ((*CUDA_LCC).isInvalid) return;\n"
"\n"
"	if (!(*CUDA_LCC).isNiter) return;\n"
"\n"
"	//if (threadIdx.x == 0)\n"
"	//{\n"
"	//	int i = 56;\n"
"	//	//for (int i = 1; i <= 60; i++)\n"
"	//	//{\n"
"	//		printf(\"[%d] alpha[%2d]: %10.7f\\n\", blockIdx.x, i, (*CUDA_LCC).alpha[i]);\n"
"	//	//}\n"
"	//}\n"
"\n"
"	//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"	//	printf(\"Mrqmin1End\\n\");\n"
"\n"
"	// gauss_err =\n"
"	//mrqmin_1_end(CUDA_LCC, CUDA_CC, sh_icol, sh_irow, sh_big, icol, pivinv);\n"
"\n"
"\n"
"	mrqmin_1_end(CUDA_LCC, CUDA_CC);\n"
"\n"
"\n"
"	//if (blockIdx.x == 0) {\n"
"	//	printf(\"[%3d] sh_icol[%3d]: %3d\\n\", threadIdx.x, threadIdx.x, sh_icol[threadIdx.x]);\n"
"	//}\n"
"}\n"
"\n"
"__kernel void ClCalculateIter1Mrqcof2Start(\n"
"	__global struct mfreq_context* CUDA_mCC,\n"
"	__global struct freq_context* CUDA_CC)\n"
"{\n"
"	int3 blockIdx, threadIdx;\n"
"	blockIdx.x = get_group_id(0);\n"
"	threadIdx.x = get_local_id(0);\n"
"\n"
"	//const auto CUDA_LCC = &CUDA_CC[blockIdx.x];\n"
"	__global struct mfreq_context* CUDA_LCC = &CUDA_mCC[blockIdx.x];\n"
"\n"
"	if ((*CUDA_LCC).isInvalid) return;\n"
"\n"
"	if (!(*CUDA_LCC).isNiter) return;\n"
"\n"
"	//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"	//	printf(\"Mrqcof2Start\\n\");\n"
"\n"
"\n"
"	//mrqcof_start(CUDA_LCC, (*CUDA_LCC).atry, (*CUDA_LCC).covar, (*CUDA_LCC).da);\n"
"	mrqcof_start(CUDA_LCC, CUDA_CC, (*CUDA_LCC).atry, (*CUDA_LCC).covar, (*CUDA_LCC).da);\n"
"\n"
"	//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"	//	printf(\"alpha[56]: %10.7f\\n\", (*CUDA_LCC).alpha[56]);\n"
"}\n"
"\n"
"__kernel void ClCalculateIter1Mrqcof2Matrix(\n"
"	__global struct mfreq_context* CUDA_mCC,\n"
"	__global struct freq_context* CUDA_CC,\n"
"	const int lpoints)\n"
"{\n"
"	int3 blockIdx, threadIdx;\n"
"	blockIdx.x = get_group_id(0);\n"
"\n"
"	//const auto CUDA_LCC = &CUDA_CC[blockIdx.x];\n"
"	__global struct mfreq_context* CUDA_LCC = &CUDA_mCC[blockIdx.x];\n"
"\n"
"	if ((*CUDA_LCC).isInvalid) return;\n"
"\n"
"	if (!(*CUDA_LCC).isNiter) return;\n"
"\n"
"	__local int num; // __shared__\n"
"\n"
"	int3 localIdx;\n"
"	localIdx.x = get_local_id(0);\n"
"	if (localIdx.x == 0)\n"
"	{\n"
"		num = 0;\n"
"	}\n"
"\n"
"	//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"	//	printf(\"Mrqcof2Matrix\\n\");\n"
"\n"
"	//mrqcof_matrix(CUDA_LCC, (*CUDA_LCC).atry, lpoints);\n"
"	mrqcof_matrix(CUDA_LCC, CUDA_CC, (*CUDA_LCC).atry, lpoints, num);\n"
"}\n"
"\n"
"__kernel void ClCalculateIter1Mrqcof2Curve1(\n"
"	__global struct mfreq_context* CUDA_mCC,\n"
"	__global struct freq_context* CUDA_CC,\n"
"	const int inrel,\n"
"	const int lpoints)\n"
"{\n"
"	int3 blockIdx, threadIdx;\n"
"	blockIdx.x = get_group_id(0);\n"
"	threadIdx.x = get_local_id(0);\n"
"\n"
"	//const auto CUDA_LCC = &CUDA_CC[blockIdx.x];\n"
"	__global struct mfreq_context* CUDA_LCC = &CUDA_mCC[blockIdx.x];\n"
"	//double* dytemp = &CUDA_Dytemp[blockIdx.x];\n"
"\n"
"	if ((*CUDA_LCC).isInvalid) return;\n"
"\n"
"	if (!(*CUDA_LCC).isNiter) return;\n"
"\n"
"	__local int num;  // __shared__\n"
"	__local double tmave[BLOCK_DIM];\n"
"\n"
"	if (threadIdx.x == 0)\n"
"	{\n"
"		num = 0;\n"
"	}\n"
"\n"
"	//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"	//	printf(\"Mrqcof2Curve1\\n\");\n"
"\n"
"	//mrqcof_curve1(CUDA_LCC, (*CUDA_LCC).atry, (*CUDA_LCC).covar, (*CUDA_LCC).da, inrel, lpoints);\n"
"	mrqcof_curve1(CUDA_LCC, CUDA_CC, (*CUDA_LCC).atry, tmave, inrel, lpoints, num);\n"
"}\n"
"\n"
"__kernel void ClCalculateIter1Mrqcof2Curve2(\n"
"	__global struct mfreq_context* CUDA_mCC,\n"
"	__global struct freq_context* CUDA_CC,\n"
"	//__global double* CUDA_Dytemp,\n"
"	const int inrel,\n"
"	const int lpoints)\n"
"{\n"
"	int3 blockIdx, threadIdx;\n"
"	blockIdx.x = get_group_id(0);\n"
"	threadIdx.x = get_local_id(0);\n"
"\n"
"	//const auto CUDA_LCC = &CUDA_CC[blockIdx.x];\n"
"	__global struct mfreq_context* CUDA_LCC = &CUDA_mCC[blockIdx.x];\n"
"\n"
"	if ((*CUDA_LCC).isInvalid) return;\n"
"\n"
"	if (!(*CUDA_LCC).isNiter) return;\n"
"\n"
"	//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"	//	printf(\"Mrqcof2Curve2\\n\");\n"
"\n"
"	mrqcof_curve2(CUDA_LCC, CUDA_CC, (*CUDA_LCC).covar, (*CUDA_LCC).da, inrel, lpoints);\n"
"}\n"
"\n"
"__kernel void ClCalculateIter1Mrqcof2Curve1Last(\n"
"	__global struct mfreq_context* CUDA_mCC,\n"
"	__global struct freq_context* CUDA_CC,\n"
"	const int inrel,\n"
"	const int lpoints)\n"
"{\n"
"	int3 blockIdx, threadIdx;\n"
"	blockIdx.x = get_group_id(0);\n"
"	threadIdx.x = get_local_id(0);\n"
"\n"
"	//const auto CUDA_LCC = &CUDA_CC[blockIdx.x];\n"
"	__global struct mfreq_context* CUDA_LCC = &CUDA_mCC[blockIdx.x];\n"
"	//double* dytemp = &CUDA_Dytemp[blockIdx.x];\n"
"\n"
"	if ((*CUDA_LCC).isInvalid) return;\n"
"\n"
"	if (!(*CUDA_LCC).isNiter) return;\n"
"\n"
"	__local double res[BLOCK_DIM];\n"
"\n"
"	//mrqcof_curve1_last(CUDA_LCC, CUDA_CC, dytemp, (*CUDA_LCC).cg, (*CUDA_LCC).alpha, (*CUDA_LCC).beta, res, inrel, lpoints);\n"
"	mrqcof_curve1_last(CUDA_LCC, CUDA_CC, (*CUDA_LCC).atry, (*CUDA_LCC).covar, (*CUDA_LCC).da, res, inrel, lpoints);\n"
"}\n"
"\n"
"__kernel void ClCalculateIter1Mrqcof2End(\n"
"	__global struct mfreq_context* CUDA_mCC,\n"
"	__global struct freq_context* CUDA_CC)\n"
"{\n"
"	int3 blockIdx, threadIdx;\n"
"	blockIdx.x = get_group_id(0);\n"
"	threadIdx.x = get_local_id(0);\n"
"\n"
"	//const auto CUDA_LCC = &CUDA_CC[blockIdx.x];\n"
"	__global struct mfreq_context* CUDA_LCC = &CUDA_mCC[blockIdx.x];\n"
"\n"
"	if ((*CUDA_LCC).isInvalid) return;\n"
"\n"
"	if (!(*CUDA_LCC).isNiter) return;\n"
"\n"
"	(*CUDA_LCC).Chisq = mrqcof_end(CUDA_LCC, CUDA_CC, (*CUDA_LCC).covar);\n"
"\n"
"	//if (blockIdx.x == 0)\n"
"	//	printf(\"[%3d] Chisq: %10.7f\\n\", threadIdx.x, (*CUDA_LCC).Chisq);\n"
"}\n"
"\n"
"__kernel void ClCalculateIter1Mrqmin2End(\n"
"	__global struct mfreq_context* CUDA_mCC,\n"
"	__global struct freq_context* CUDA_CC)\n"
"{\n"
"	int3 blockIdx, threadIdx;\n"
"	blockIdx.x = get_group_id(0);\n"
"	threadIdx.x = get_local_id(0);\n"
"\n"
"	//const auto CUDA_LCC = &CUDA_CC[blockIdx.x];\n"
"	__global struct mfreq_context* CUDA_LCC = &CUDA_mCC[blockIdx.x];\n"
"\n"
"	if ((*CUDA_LCC).isInvalid) return;\n"
"\n"
"	if (!(*CUDA_LCC).isNiter) return;\n"
"\n"
"	//if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"	//	printf(\"Mrqmin2End\\n\");\n"
"\n"
"	//mrqmin_2_end(CUDA_LCC, CUDA_ia, CUDA_ma);\n"
"	mrqmin_2_end(CUDA_LCC, CUDA_CC);\n"
"\n"
"	(*CUDA_LCC).Niter++;\n"
"\n"
"	//if (blockIdx.x == 0)\n"
"	//	printf(\"[%3d] Niter: %d\\n\", threadIdx.x, (*CUDA_LCC).Niter);\n"
"	//printf(\"|\");\n"
"}\n"
"\n"
"__kernel void ClCalculateIter2(\n"
"	__global struct mfreq_context* CUDA_mCC,\n"
"	__global struct freq_context* CUDA_CC)\n"
"{\n"
"	int i, j;\n"
"	int3 blockIdx, threadIdx;\n"
"	blockIdx.x = get_group_id(0);\n"
"	threadIdx.x = get_local_id(0);\n"
"\n"
"	//const auto CUDA_LCC = &CUDA_CC[blockIdx.x];\n"
"	__global struct mfreq_context* CUDA_LCC = &CUDA_mCC[blockIdx.x];\n"
"\n"
"	if ((*CUDA_LCC).isInvalid)\n"
"	{\n"
"		return;\n"
"	}\n"
"\n"
"	//if (blockIdx.x == 0)\n"
"	//	printf(\"[%3d] isNiter: %d\\n\", threadIdx.x, (*CUDA_LCC).isNiter);\n"
"\n"
"	if ((*CUDA_LCC).isNiter)\n"
"	{\n"
"		if ((*CUDA_LCC).Niter == 1 || (*CUDA_LCC).Chisq < (*CUDA_LCC).Ochisq)\n"
"		{\n"
"			if (threadIdx.x == 0)\n"
"			{\n"
"				(*CUDA_LCC).Ochisq = (*CUDA_LCC).Chisq;\n"
"			}\n"
"\n"
"			barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); //__syncthreads();\n"
"\n"
"			int brtmph = (*CUDA_CC).Numfac / BLOCK_DIM;\n"
"			if ((*CUDA_CC).Numfac % BLOCK_DIM) brtmph++;\n"
"			int brtmpl = threadIdx.x * brtmph;\n"
"			brtmph = brtmpl + brtmph;\n"
"			if (brtmph > (*CUDA_CC).Numfac) brtmph = (*CUDA_CC).Numfac;\n"
"			brtmpl++;\n"
"\n"
"			curv(CUDA_LCC, CUDA_CC, (*CUDA_LCC).cg, brtmpl, brtmph);\n"
"\n"
"			if (threadIdx.x == 0)\n"
"			{\n"
"				for (i = 1; i <= 3; i++)\n"
"				{\n"
"					(*CUDA_LCC).chck[i] = 0;\n"
"\n"
"\n"
"					for (j = 1; j <= (*CUDA_CC).Numfac; j++)\n"
"					{\n"
"						double qq;\n"
"						qq = (*CUDA_LCC).chck[i] + (*CUDA_LCC).Area[j] * (*CUDA_CC).Nor[j][i - 1];\n"
"\n"
"						//if (blockIdx.x == 0)\n"
"						//	printf(\"[%d] [%d][%3d] qq: %10.7f, chck[%d]: %10.7f, Area[%3d]: %10.7f, Nor[%3d][%d]: %10.7f\\n\",\n"
"						//		blockIdx.x, i, j, qq, i, (*CUDA_LCC).chck[i], j, (*CUDA_LCC).Area[j], j, i - 1, (*CUDA_CC).Nor[j][i - 1]);\n"
"\n"
"						(*CUDA_LCC).chck[i] = qq;\n"
"					}\n"
"\n"
"					//if (blockIdx.x == 0)\n"
"					//	printf(\"[%d] chck[%d]: %10.7f\\n\", blockIdx.x, i, (*CUDA_LCC).chck[i]);\n"
"				}\n"
"\n"
"				//printf(\"[%d] chck[1]: %10.7f, chck[2]: %10.7f, chck[3]: %10.7f\\n\", blockIdx.x, (*CUDA_LCC).chck[1], (*CUDA_LCC).chck[2], (*CUDA_LCC).chck[3]);\n"
"\n"
"				(*CUDA_LCC).rchisq = (*CUDA_LCC).Chisq - (pow((*CUDA_LCC).chck[1], 2.0) + pow((*CUDA_LCC).chck[2], 2.0) + pow((*CUDA_LCC).chck[3], 2.0)) * pow((*CUDA_CC).conw_r, 2.0);\n"
"				//(*CUDA_LCC).rchisq = (*CUDA_LCC).Chisq - ((*CUDA_LCC).chck[1] * (*CUDA_LCC).chck[1] + (*CUDA_LCC).chck[2] * (*CUDA_LCC).chck[2] + (*CUDA_LCC).chck[3] * (*CUDA_LCC).chck[3]) * ((*CUDA_CC).conw_r * (*CUDA_CC).conw_r);\n"
"			}\n"
"		}\n"
"\n"
"		barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); // TEST\n"
"\n"
"		if (threadIdx.x == 0)\n"
"		{\n"
"			//if (blockIdx.x == 0)\n"
"			//	printf(\"ndata - 3: %3d\\n\", (*CUDA_CC).ndata - 3);\n"
"\n"
"			(*CUDA_LCC).dev_new = sqrt((*CUDA_LCC).rchisq / ((*CUDA_CC).ndata - 3));\n"
"\n"
"			//if (blockIdx.x == 233)\n"
"			//{\n"
"			//	double dev_best = (*CUDA_LCC).dev_new * (*CUDA_LCC).dev_new * ((*CUDA_CC).ndata - 3);\n"
"			//	printf(\"[%3d] rchisq: %12.8f, ndata-3: %3d, dev_new: %12.8f, dev_best: %12.8f\\n\",\n"
"			//		blockIdx.x, (*CUDA_LCC).rchisq, (*CUDA_CC).ndata - 3, (*CUDA_LCC).dev_new, dev_best);\n"
"			//}\n"
"\n"
"			// NOTE: only if this step is better than the previous, 1e-10 is for numeric errors\n"
"			if ((*CUDA_LCC).dev_old - (*CUDA_LCC).dev_new > 1e-10)\n"
"			{\n"
"				(*CUDA_LCC).iter_diff = (*CUDA_LCC).dev_old - (*CUDA_LCC).dev_new;\n"
"				(*CUDA_LCC).dev_old = (*CUDA_LCC).dev_new;\n"
"			}\n"
"			//		(*CUDA_LFR).Niter=(*CUDA_LCC).Niter;\n"
"		}\n"
"\n"
"		barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE); // TEST\n"
"	}\n"
"}\n"
"\n"
"__kernel void ClCalculateFinishPole(\n"
"	__global struct mfreq_context* CUDA_mCC,\n"
"	__global struct freq_context* CUDA_CC,\n"
"	__global struct freq_result* CUDA_FR)\n"
"{\n"
"	int i;\n"
"	int3 blockIdx;\n"
"	blockIdx.x = get_group_id(0);\n"
"\n"
"	//const auto CUDA_LCC = &CUDA_CC[blockIdx.x];\n"
"	//const auto CUDA_LFR = &CUDA_FR[blockIdx.x];\n"
"	__global struct mfreq_context* CUDA_LCC = &CUDA_mCC[blockIdx.x];\n"
"	__global struct freq_result* CUDA_LFR = &CUDA_FR[blockIdx.x];\n"
"\n"
"	if ((*CUDA_LCC).isInvalid) return;\n"
"\n"
"	double totarea = 0;\n"
"	for (i = 1; i <= (*CUDA_CC).Numfac; i++)\n"
"	{\n"
"		totarea = totarea + (*CUDA_LCC).Area[i];\n"
"	}\n"
"\n"
"	//if(blockIdx.x == 2)\n"
"	//	printf(\"[%d] chck[1]: %10.7f, chck[2]: %10.7f, chck[3]: %10.7f, conw_r: %10.7f\\n\", blockIdx.x, (*CUDA_LCC).chck[1], (*CUDA_LCC).chck[2], (*CUDA_LCC).chck[3], (*CUDA_CC).conw_r);\n"
"\n"
"	//if (blockIdx.x == 2)\n"
"	//	printf(\"rchisq: %10.7f, Chisq: %10.7f \\n\", (*CUDA_LCC).rchisq, (*CUDA_LCC).Chisq);\n"
"\n"
"	//const double sum = pow((*CUDA_LCC).chck[1], 2.0) + pow((*CUDA_LCC).chck[2], 2.0) + pow((*CUDA_LCC).chck[3], 2.0);\n"
"	const double sum = ((*CUDA_LCC).chck[1] * (*CUDA_LCC).chck[1]) + ((*CUDA_LCC).chck[2] * (*CUDA_LCC).chck[2]) + ((*CUDA_LCC).chck[3] * (*CUDA_LCC).chck[3]);\n"
"	//printf(\"[FinishPole] [%d] sum: %10.7f\\n\", blockIdx.x, sum);\n"
"\n"
"	const double dark = sqrt(sum);\n"
"\n"
"	//if (blockIdx.x == 232 || blockIdx.x == 233)\n"
"	//	printf(\"[%d] sum: %12.8f, dark: %12.8f, totarea: %12.8f, dark_best: %12.8f\\n\", blockIdx.x, sum, dark, totarea, dark / totarea * 100);\n"
"\n"
"	/* period solution */\n"
"	const double period = 2 * PI / (*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 3];\n"
"\n"
"	/* pole solution */\n"
"	const double la_tmp = RAD2DEG * (*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 2];\n"
"\n"
"	//if (la_tmp < 0.0)\n"
"	//	printf(\"[CalculateFinishPole] la_best: %4.0f\\n\", la_tmp);\n"
"\n"
"	const double be_tmp = 90 - RAD2DEG * (*CUDA_LCC).cg[(*CUDA_CC).Ncoef + 1];\n"
"\n"
"	//if (blockIdx.x == 2)\n"
"		//printf(\"[%d] dev_new: %10.7f, dev_best: %10.7f\\n\", blockIdx.x, (*CUDA_LCC).dev_new, (*CUDA_LFR).dev_best);\n"
"\n"
"	if ((*CUDA_LCC).dev_new < (*CUDA_LFR).dev_best)\n"
"	{\n"
"		(*CUDA_LFR).dev_best = (*CUDA_LCC).dev_new;\n"
"		(*CUDA_LFR).dev_best_x2 = (*CUDA_LCC).rchisq;\n"
"		(*CUDA_LFR).per_best = period;\n"
"		(*CUDA_LFR).dark_best = dark / totarea * 100;\n"
"		(*CUDA_LFR).la_best = la_tmp;\n"
"		(*CUDA_LFR).be_best = be_tmp;\n"
"\n"
"		//printf(\"[%d] dev_best: %12.8f\\n\", blockIdx.x, (*CUDA_LFR).dev_best);\n"
"\n"
"		//if (blockIdx.x == 232)\n"
"		//{\n"
"		//	double dev_best = (*CUDA_LFR).dev_best * (*CUDA_LFR).dev_best * ((*CUDA_CC).ndata - 3);\n"
"		//	printf(\"[%3d] rchisq: %12.8f, ndata-3: %3d, dev_new: %12.8f, dev_best: %12.8f\\n\",\n"
"		//		blockIdx.x, (*CUDA_LCC).rchisq, (*CUDA_CC).ndata - 3, (*CUDA_LFR).dev_best, dev_best);\n"
"		//}\n"
"	}\n"
"\n"
"	//if (blockIdx.x == 2)\n"
"	//	printf(\"dark_best: %10.7f \\n\", (*CUDA_LFR).dark_best);\n"
"\n"
"	//debug\n"
"	/*	(*CUDA_LFR).dark=dark;\n"
"	(*CUDA_LFR).totarea=totarea;\n"
"	(*CUDA_LFR).chck[1]=(*CUDA_LCC).chck[1];\n"
"	(*CUDA_LFR).chck[2]=(*CUDA_LCC).chck[2];\n"
"	(*CUDA_LFR).chck[3]=(*CUDA_LCC).chck[3];*/\n"
"}\n"
"\n"
"__kernel void ClCalculateFinish(\n"
"	__global struct mfreq_context* CUDA_mCC,\n"
"	__global struct freq_result* CUDA_FR)\n"
"{\n"
"	int3 blockIdx;\n"
"	blockIdx.x = get_group_id(0);\n"
"\n"
"	//const auto CUDA_LCC = &CUDA_CC[blockIdx.x];\n"
"	//const auto CUDA_LFR = &CUDA_FR[blockIdx.x];\n"
"\n"
"	__global struct mfreq_context* CUDA_LCC = &CUDA_mCC[blockIdx.x];\n"
"	__global struct freq_result* CUDA_LFR = &CUDA_FR[blockIdx.x];\n"
"\n"
"	if ((*CUDA_LCC).isInvalid) return;\n"
"\n"
"	if ((*CUDA_LFR).la_best < 0.0)\n"
"	{\n"
"		//double tmp = (*CUDA_LFR).la_best;\n"
"		(*CUDA_LFR).la_best += 360;\n"
"		//printf(\"[CalculateFinish] la_best: %4.0f -> %4.0f\\n\", tmp, (*CUDA_LFR).la_best);\n"
"	}\n"
"\n"
"	if (isnan((*CUDA_LFR).dark_best) == 1)\n"
"	{\n"
"		(*CUDA_LFR).dark_best = 1.0;\n"
"	}\n"
"}\n";
